<!DOCTYPE html>

<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="mobile-web-app-capable" content="yes">
    <title>
        Chương 19: suy luận xấp xỉ - HackMD
    </title>
    <link rel="icon" type="image/png" href="https://hackmd.io/favicon.png">
    <link rel="apple-touch-icon" href="https://hackmd.io/apple-touch-icon.png">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ionicons/2.0.1/css/ionicons.min.css" integrity="sha256-3iu9jgsy9TpTwXKb7bNQzqWekRX7pPK+2OLj3R922fo=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/octicons/3.5.0/octicons.min.css" integrity="sha256-QiWfLIsCT02Sdwkogf6YMiQlj4NE84MKkzEMkZnMGdg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.1/themes/prism.min.css" integrity="sha256-vtR0hSWRc3Tb26iuN2oZHt3KRUomwTufNIf5/4oeCyg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/emojify.js/1.1.0/css/basic/emojify.min.css" integrity="sha256-UOrvMOsSDSrW6szVLe8ZDZezBxh5IoIfgTwdNDgTjiU=" crossorigin="anonymous" />
    <style>
        @import url(https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i|Source+Code+Pro:300,400,500|Source+Sans+Pro:300,300i,400,400i,600,600i|Source+Serif+Pro&subset=latin-ext);.hljs{display:block;background:#fff;padding:.5em;color:#333;overflow-x:auto}.hljs-comment,.hljs-meta{color:#969896}.hljs-emphasis,.hljs-quote,.hljs-string,.hljs-strong,.hljs-template-variable,.hljs-variable{color:#df5000}.hljs-keyword,.hljs-selector-tag,.hljs-type{color:#a71d5d}.hljs-attribute,.hljs-bullet,.hljs-literal,.hljs-number,.hljs-symbol{color:#0086b3}.hljs-built_in,.hljs-builtin-name{color:#005cc5}.hljs-name,.hljs-section{color:#63a35c}.hljs-tag{color:#333}.hljs-attr,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-selector-pseudo,.hljs-title{color:#795da3}.hljs-addition{color:#55a532;background-color:#eaffea}.hljs-deletion{color:#bd2c00;background-color:#ffecec}.hljs-link{text-decoration:underline}.markdown-body{font-size:16px;line-height:1.5;word-wrap:break-word}.markdown-body:after,.markdown-body:before{display:table;content:""}.markdown-body:after{clear:both}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:#c00}.markdown-body .anchor{float:left;padding-right:4px;margin-left:-20px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body blockquote,.markdown-body dl,.markdown-body ol,.markdown-body p,.markdown-body pre,.markdown-body table,.markdown-body ul{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;padding:0;margin:24px 0;background-color:#e7e7e7;border:0}.markdown-body blockquote{font-size:16px;padding:0 1em;color:#777;border-left:.25em solid #ddd}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body .loweralpha{list-style-type:lower-alpha}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:#000;vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 code,.markdown-body h1 tt,.markdown-body h2 code,.markdown-body h2 tt,.markdown-body h3 code,.markdown-body h3 tt,.markdown-body h4 code,.markdown-body h4 tt,.markdown-body h5 code,.markdown-body h5 tt,.markdown-body h6 code,.markdown-body h6 tt{font-size:inherit}.markdown-body h1{font-size:2em}.markdown-body h1,.markdown-body h2{padding-bottom:.3em;border-bottom:1px solid #eee}.markdown-body h2{font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{font-size:.85em;color:#777}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body ol.no-list,.markdown-body ul.no-list{padding:0;list-style-type:none}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{margin-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}.markdown-body dl dd{padding:0 16px;margin-bottom:16px}.markdown-body table{display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}.markdown-body table th{font-weight:700}.markdown-body table td,.markdown-body table th{padding:6px 13px;border:1px solid #ddd}.markdown-body table tr{background-color:#fff;border-top:1px solid #ccc}.markdown-body table tr:nth-child(2n){background-color:#f8f8f8}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:#fff}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:transparent}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{display:block;float:left;width:auto;padding:7px;margin:13px 0 0;overflow:hidden;border:1px solid #ddd}.markdown-body span.frame span img{display:block;float:left}.markdown-body span.frame span span{display:block;padding:5px 0 0;clear:both;color:#333}.markdown-body span.align-center{display:block;overflow:hidden;clear:both}.markdown-body span.align-center>span{display:block;margin:13px auto 0;overflow:hidden;text-align:center}.markdown-body span.align-center span img{margin:0 auto;text-align:center}.markdown-body span.align-right{display:block;overflow:hidden;clear:both}.markdown-body span.align-right>span{display:block;margin:13px 0 0;overflow:hidden;text-align:right}.markdown-body span.align-right span img{margin:0;text-align:right}.markdown-body span.float-left{display:block;float:left;margin-right:13px;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{display:block;float:right;margin-left:13px;overflow:hidden}.markdown-body span.float-right>span{display:block;margin:13px auto 0;overflow:hidden;text-align:right}.markdown-body code,.markdown-body tt{padding:0;padding-top:.2em;padding-bottom:.2em;margin:0;font-size:85%;background-color:rgba(0,0,0,.04);border-radius:3px}.markdown-body code:after,.markdown-body code:before,.markdown-body tt:after,.markdown-body tt:before{letter-spacing:-.2em;content:"\00a0"}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{text-decoration:inherit}.markdown-body pre{word-wrap:normal}.markdown-body pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:transparent;border:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{margin-bottom:0;word-break:normal}.markdown-body .highlight pre,.markdown-body pre{padding:16px;overflow:auto;font-size:85%;line-height:1.45;background-color:#f7f7f7;border-radius:3px}.markdown-body pre code,.markdown-body pre tt{display:inline;max-width:auto;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}.markdown-body pre code:after,.markdown-body pre code:before,.markdown-body pre tt:after,.markdown-body pre tt:before{content:normal}.markdown-body .csv-data td,.markdown-body .csv-data th{padding:5px;overflow:hidden;font-size:12px;line-height:1;text-align:left;white-space:nowrap}.markdown-body .csv-data .blob-line-num{padding:10px 8px 9px;text-align:right;background:#fff;border:0}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{font-weight:700;background:#f8f8f8;border-top:0}.markdown-body kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#555;vertical-align:middle;background-color:#fcfcfc;border:1px solid #ccc;border-bottom-color:#bbb;border-radius:3px;box-shadow:inset 0 -1px 0 #bbb}.news .alert .markdown-body blockquote{padding:0 0 0 40px;border:0 none}.activity-tab .news .alert .commits,.activity-tab .news .markdown-body blockquote{padding-left:0}.task-list-item{list-style-type:none}.task-list-item label{font-weight:400}.task-list-item.enabled label{cursor:pointer}.task-list-item+.task-list-item{margin-top:3px}.task-list-item-checkbox{float:left;margin:.31em 0 .2em -1.3em!important;vertical-align:middle;cursor:default!important}.markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,sans-serif;padding-top:40px;padding-bottom:40px;max-width:758px;overflow:visible!important}.markdown-body .emoji{vertical-align:top}.markdown-body pre{border:inherit!important}.markdown-body code{color:inherit!important}.markdown-body pre code .wrapper{display:-moz-inline-flex;display:-ms-inline-flex;display:-o-inline-flex;display:inline-flex}.markdown-body pre code .gutter{float:left;overflow:hidden;-webkit-user-select:none;user-select:none}.markdown-body pre code .gutter.linenumber{text-align:right;position:relative;display:inline-block;cursor:default;z-index:4;padding:0 8px 0 0;min-width:20px;box-sizing:content-box;color:#afafaf!important;border-right:3px solid #6ce26c!important}.markdown-body pre code .gutter.linenumber>span:before{content:attr(data-linenumber)}.markdown-body pre code .code{float:left;margin:0 0 0 16px}.markdown-body .gist .line-numbers{border-left:none;border-top:none;border-bottom:none}.markdown-body .gist .line-data{border:none}.markdown-body .gist table{border-spacing:0;border-collapse:inherit!important}.markdown-body code[data-gist-id]{background:none;padding:0}.markdown-body code[data-gist-id]:after,.markdown-body code[data-gist-id]:before{content:""}.markdown-body code[data-gist-id] .blob-num{border:unset}.markdown-body code[data-gist-id] table{overflow:unset;margin-bottom:unset}.markdown-body code[data-gist-id] table tr{background:unset}.markdown-body[dir=rtl] pre{direction:ltr}.markdown-body[dir=rtl] code{direction:ltr;unicode-bidi:embed}.markdown-body .alert>p{margin-bottom:0}.markdown-body pre.abc,.markdown-body pre.flow-chart,.markdown-body pre.graphviz,.markdown-body pre.mermaid,.markdown-body pre.sequence-diagram{text-align:center;background-color:inherit;border-radius:0;white-space:inherit}.markdown-body pre.abc>code,.markdown-body pre.flow-chart>code,.markdown-body pre.graphviz>code,.markdown-body pre.mermaid>code,.markdown-body pre.sequence-diagram>code{text-align:left}.markdown-body pre.abc>svg,.markdown-body pre.flow-chart>svg,.markdown-body pre.graphviz>svg,.markdown-body pre.mermaid>svg,.markdown-body pre.sequence-diagram>svg{max-width:100%;height:100%}.markdown-body pre>code.wrap{white-space:pre-wrap;white-space:-moz-pre-wrap;white-space:-pre-wrap;white-space:-o-pre-wrap;word-wrap:break-word}.markdown-body .alert>p,.markdown-body .alert>ul{margin-bottom:0}.markdown-body summary{display:list-item}.markdown-body summary:focus{outline:none}.markdown-body details summary{cursor:pointer}.markdown-body details:not([open])>:not(summary){display:none}.markdown-body figure{margin:1em 40px}.markdown-body .mark,.markdown-body mark{background-color:#fff1a7}.vimeo,.youtube{cursor:pointer;display:table;text-align:center;background-position:50%;background-repeat:no-repeat;background-size:contain;background-color:#000;overflow:hidden}.vimeo,.youtube{position:relative;width:100%}.youtube{padding-bottom:56.25%}.vimeo img{width:100%;object-fit:contain;z-index:0}.youtube img{object-fit:cover;z-index:0}.vimeo iframe,.youtube iframe,.youtube img{width:100%;height:100%;position:absolute;top:0;left:0}.vimeo iframe,.youtube iframe{vertical-align:middle;z-index:1}.vimeo .icon,.youtube .icon{position:absolute;height:auto;width:auto;top:50%;left:50%;transform:translate(-50%,-50%);color:#fff;opacity:.3;transition:opacity .2s;z-index:0}.vimeo:hover .icon,.youtube:hover .icon{opacity:.6;transition:opacity .2s}.slideshare .inner,.speakerdeck .inner{position:relative;width:100%}.slideshare .inner iframe,.speakerdeck .inner iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%}.MJX_Assistive_MathML{display:none}.ui-infobar{position:relative;z-index:2;max-width:760px;margin:25px auto -25px;padding:0 15px;color:#777}.toc .invisable-node{list-style-type:none}.ui-toc{position:fixed;bottom:20px;z-index:998}.ui-toc-label{opacity:.3;background-color:#ccc;border:none;transition:opacity .2s}.ui-toc .open .ui-toc-label{opacity:1;color:#fff;transition:opacity .2s}.ui-toc-label:focus{opacity:.3;background-color:#ccc;color:#000}.ui-toc-label:hover{opacity:1;background-color:#ccc;transition:opacity .2s}.ui-toc-dropdown{margin-top:23px;margin-bottom:20px;padding-left:10px;padding-right:10px;max-width:45vw;width:25vw;max-height:70vh;overflow:auto;text-align:inherit}.ui-toc-dropdown>.toc{max-height:calc(70vh - 100px);overflow:auto}.ui-toc-dropdown[dir=rtl] .nav{padding-right:0;letter-spacing:.0029em}.ui-toc-dropdown a{overflow:hidden;text-overflow:ellipsis;white-space:pre}.ui-toc-dropdown .nav>li>a{display:block;padding:4px 20px;font-size:13px;font-weight:500;color:#767676}.ui-toc-dropdown .nav>li:first-child:last-child > ul,.ui-toc-dropdown .toc.expand ul{display:block}.ui-toc-dropdown .nav>li>a:focus,.ui-toc-dropdown .nav>li>a:hover{padding-left:19px;color:#000;text-decoration:none;background-color:transparent;border-left:1px solid #000}.ui-toc-dropdown[dir=rtl] .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav>li>a:hover{padding-right:19px;border-left:none;border-right:1px solid #000}.ui-toc-dropdown .nav>.active:focus>a,.ui-toc-dropdown .nav>.active:hover>a,.ui-toc-dropdown .nav>.active>a{padding-left:18px;font-weight:700;color:#000;background-color:transparent;border-left:2px solid #000}.ui-toc-dropdown[dir=rtl] .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav>.active>a{padding-right:18px;border-left:none;border-right:2px solid #000}.ui-toc-dropdown .nav .nav{display:none;padding-bottom:10px}.ui-toc-dropdown .nav>.active>ul{display:block}.ui-toc-dropdown .nav .nav>li>a{padding-top:1px;padding-bottom:1px;padding-left:30px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a{padding-right:30px}.ui-toc-dropdown .nav .nav>li>ul>li>a{padding-top:1px;padding-bottom:1px;padding-left:40px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a{padding-right:40px}.ui-toc-dropdown .nav .nav>li>a:focus,.ui-toc-dropdown .nav .nav>li>a:hover{padding-left:29px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:hover{padding-right:29px}.ui-toc-dropdown .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown .nav .nav>li>ul>li>a:hover{padding-left:39px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:hover{padding-right:39px}.ui-toc-dropdown .nav .nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>a{padding-left:28px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>a{padding-right:28px}.ui-toc-dropdown .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active>a{padding-left:38px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active>a{padding-right:38px}.markdown-body[lang^=ja]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}.ui-toc-dropdown[lang^=ja]{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}.markdown-body[lang=zh-tw]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}.ui-toc-dropdown[lang=zh-tw]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}.markdown-body[lang=zh-cn]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}.ui-toc-dropdown[lang=zh-cn]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}.ui-affix-toc{position:fixed;top:0;max-width:15vw;max-height:70vh;overflow:auto}.back-to-top,.expand-toggle,.go-to-bottom{display:block;padding:4px 10px;margin-top:10px;margin-left:10px;font-size:12px;font-weight:500;color:#999}.back-to-top:focus,.back-to-top:hover,.expand-toggle:focus,.expand-toggle:hover,.go-to-bottom:focus,.go-to-bottom:hover{color:#563d7c;text-decoration:none}.back-to-top,.go-to-bottom{margin-top:0}.ui-user-icon{width:20px;height:20px;display:block;border-radius:3px;margin-top:2px;margin-bottom:2px;margin-right:5px;background-position:50%;background-repeat:no-repeat;background-size:cover}.ui-user-icon.small{width:18px;height:18px;display:inline-block;vertical-align:middle;margin:0 0 .2em}.ui-infobar>small>span{line-height:22px}.ui-infobar>small .dropdown{display:inline-block}.ui-infobar>small .dropdown a:focus,.ui-infobar>small .dropdown a:hover{text-decoration:none}.unselectable{-webkit-user-select:none;-o-user-select:none;user-select:none}@media print{blockquote,div,img,pre,table{page-break-inside:avoid!important}a[href]:after{font-size:12px!important}}.markdown-body.slides{position:relative;z-index:1;color:#222}.markdown-body.slides:before{content:"";display:block;position:absolute;top:0;left:0;right:0;bottom:0;z-index:-1;background-color:currentColor;box-shadow:0 0 0 50vw}.markdown-body.slides section[data-markdown]{position:relative;margin-bottom:1.5em;background-color:#fff;text-align:center}.markdown-body.slides section[data-markdown] code{text-align:left}.markdown-body.slides section[data-markdown]:before{content:"";display:block;padding-bottom:56.23%}.markdown-body.slides section[data-markdown]>div:first-child{position:absolute;top:50%;left:1em;right:1em;transform:translateY(-50%);max-height:100%;overflow:hidden}.markdown-body.slides section[data-markdown]>ul{display:inline-block}.markdown-body.slides>section>section+section:after{content:"";position:absolute;top:-1.5em;right:1em;height:1.5em;border:3px solid #777}body{font-smoothing:subpixel-antialiased!important;-webkit-font-smoothing:subpixel-antialiased!important;-moz-osx-font-smoothing:auto!important;text-shadow:0 0 1em transparent,1px 1px 1.2px rgba(0,0,0,.004);-webkit-overflow-scrolling:touch;font-family:Source Sans Pro,Helvetica,Arial,sans-serif;letter-spacing:.025em}.focus,:focus{outline:none!important}::-moz-focus-inner{border:0!important}body.modal-open{overflow-y:auto;padding-right:0!important}
    </style>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" integrity="sha256-3Jy/GbSLrg0o9y5Z5n1uw0qxZECH7C6OQpVBgNFYa0g=" crossorigin="anonymous"></script>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js" integrity="sha256-g6iAfvZp+nDQ2TdTR/VVKJf3bGro4ub5fvWSWVRi2NE=" crossorigin="anonymous"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js" integrity="sha256-8E4Is26QH0bD52WoQpcB+R/tcWQtpzlCojrybUd7Mxo=" crossorigin="anonymous"></script>
    <![endif]-->
</head>

<body>
    <div id="doc" class="markdown-body container-fluid comment-enabled"><h1 id="Chương-19-suy-luận-xấp-xỉ"><a class="anchor hidden-xs" href="#Chương-19-suy-luận-xấp-xỉ" title="Chương-19-suy-luận-xấp-xỉ"><span class="octicon octicon-link"></span></a>Chương 19: suy luận xấp xỉ</h1><p>Bản backup: <a href="https://hackmd.io/bUUKI92YTNWXCpSUCkbQew" target="_blank" rel="noopener">https://hackmd.io/bUUKI92YTNWXCpSUCkbQew</a></p><p>----- Trung bắt đầu dịch từ đây ------<br>
----- bắt đầu trang 629 ------<br>
Nhiều mô hình xác suất khó có thể huấn luyện được vì rất khó thực hiện quá trình suy luận trong chúng. Trong bối cảnh học sâu, chúng ta thường có một tập hợp các biến khả kiến <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-2">v</span></span></span><script type="math/tex" id="MathJax-Element-1">\boldsymbol{v}</script></span> và một tập hợp các biến ẩn <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-3"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-4">h</span></span></span><script type="math/tex" id="MathJax-Element-2">\boldsymbol{h}</script></span>. Thách thức của việc suy luận thường tham chiếu đến vấn đề khó khăn trong việc tính toán <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-5"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-6">p</span></span></span><script type="math/tex" id="MathJax-Element-3">p</script></span>(<span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-7"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-8">h</span></span></span><script type="math/tex" id="MathJax-Element-4">\boldsymbol{h}</script></span> | <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-9"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-10">v</span></span></span><script type="math/tex" id="MathJax-Element-5">\boldsymbol{v}</script></span>) hoặc tính những kỳ vọng theo nó. Các phép toán này thường cần thiết cho các tác vụ như học hợp lý cực đại.</p><p>Nhiều mô hình đồ thị đơn giản chỉ có một tầng ẩn, chẳng hạn như máy Boltzmann thu hẹp và PCA xác suất, được định nghĩa theo một cách để các phép toán suy luận như tính toán <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-11"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12">p</span></span></span><script type="math/tex" id="MathJax-Element-6">p</script></span>(<span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-13"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-14">h</span></span></span><script type="math/tex" id="MathJax-Element-7">\boldsymbol{h}</script></span> | <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-15"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-16">v</span></span></span><script type="math/tex" id="MathJax-Element-8">\boldsymbol{v}</script></span>), hoặc phép lấy kỳ vọng theo nó, trở nên đơn giản. Thật kkhông may, phần lớn các mô hình đồ thị gồm nhiều tầng của các biến ẩn có phân phối hậu nghiệm khó tính toán. Phép suy luận chính xác đòi hỏi một lượng thời gian theo hàm số mũ trong các mô hình này. Thậm chí là những mô hình đơn tầng, chẳng hạn như mã hoá thưa, cũng gặp phải vấn đề này.</p><p>Trong chương này, chúng tôi giới thiệu một số kỹ thuật để đối phó với những vấn đề suy luận khó tính toán này. Trong chương 20, chúng tôi mô tả cách sử dụng các kỹ thuật này để huấn luyện các mô hình xác xuất khó tính toán, chẳng hạn như mạng phân phối đa tầng và các máy Boltzmann đa tầng.</p><p>Các vấn đề suy luận khó tính toán trong học sâu thường phát sinh từ sự tương tác giữa các biến ẩn trong mô hình đồ thị có cấu trúc. Một số ví dụ được giới thiệu trong hình 19.1. Những tương tác này có thể là do các tương tác trực tiếp trong các mô hình vô hướng hoặc các tương tác “thanh minh” giữa các nút cha của cùng một đơn vị khả kiến trong các mô hình có hướng.</p><p><img src="https://i.imgur.com/GHHCL58.png" alt=""></p><blockquote>
<blockquote>
<p>Hình 19.1: Các vấn đề suy luận khó tính toán trong học sâu thường là kết quả của các tương tác giữa các biến ẩn trong mô hình đồ thị có cấu trúc. Những tương tác này có thể do các cạnh kết nối trực tiếp các biến ẩn với nhau hoặc các đường dẫn dài hơn được kích hoạt khi nút con trong cấu trúc chữ V được quan sát. (Bên trái) Một <strong>máy Boltzmann bán hạn chế</strong> (Osindero và Hinto, 2008) với các kết nối giữa các đơn vị ẩn. Những liên kết trực tiếp giữa các biến ẩn làm cho phân phối hậu nghiệm trở nên khó tính toán bởi vì những liên kết lớn của các biến ẩn. (Giữa) Một máy Boltmann đa tầng, được tổ chức thành các tầng mà không có các kết nối nội tầng, vẫn có một phân phối hậu nghiệm khó tính toán do các kết nối giữa các tầng. (Phải) Mô hình có huớng này có các tương tác giữa các biến ẩn khi quan sát các biến khả kiến, do mỗi một cặp biến ẩn đều cùng là nút cha của một biến khả kiến nào đó. Một số mô hình xác suất có thể cung cấp quá trình suy luận dễ tính toán theo các biến ẩn mặc dù có cấu trúc đồ thị thuộc một trong nhưng loại miêu tả ở trên. Điều này hoàn toàn có khả năng xảy ra nếu những phân phối xác suất có điều kiện được lựa chọn để đưa ra các độc lập bổ sung ngoài những độc lập được mô tả trong đồ thị.<br>
Ví dụ, PCA xác suất có cấu trúc đồ thị như hình bên phải nhưng vẫn có phép suy luận đơn giản do các thuộc tính đặc biệt của các phân phối có điều kiện đặc thù mà nó sử dụng (các hàm Gauss tuyến tính có điều kiện với các vector cơ sở trực giao lẫn nhau)</p>
</blockquote>
<blockquote></blockquote>
</blockquote><h2 id="191-Suy-luận-như-là-Tối-ưu-hóa"><a class="anchor hidden-xs" href="#191-Suy-luận-như-là-Tối-ưu-hóa" title="191-Suy-luận-như-là-Tối-ưu-hóa"><span class="octicon octicon-link"></span></a>19.1 Suy luận như là Tối ưu hóa</h2><p>Có nhiều cách tiếp cận để đối mặt với vấn đề suy luận khó tính toán dựa trên một nhận định rằng suy luận chính xác có thể được biểu diễn thành một bài toán tối ưu. Các thuật toán suy luận xấp xỉ khi đó có thể được suy ra bằng cách xấp xỉ bài toán tối ưu cận dưới.</p><p>Để xây dựng bài toán tối ưu, giả sử chúng ta có một mô hình xác suất bao gồm các biến khả kiến <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-17"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-18">v</span></span></span><script type="math/tex" id="MathJax-Element-9">\boldsymbol{v}</script></span> và các biến ẩn <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-19"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-20">h</span></span></span><script type="math/tex" id="MathJax-Element-10">\boldsymbol{h}</script></span>. Ta muốn tính logarit xác suất của dữ liệu khả kiến <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-21"><span class="MJXp-mi" id="MJXp-Span-22">log</span><span class="MJXp-mspace" id="MJXp-Span-23" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24">p</span><span class="MJXp-mo" id="MJXp-Span-25" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-26">v</span><span class="MJXp-mo" id="MJXp-Span-27" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-28">θ</span><span class="MJXp-mo" id="MJXp-Span-29" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-11">\log\,p(\boldsymbol{v};\boldsymbol{\theta})</script></span>. Đôi khi rất khó để tính được <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-30"><span class="MJXp-mi" id="MJXp-Span-31">log</span><span class="MJXp-mo" id="MJXp-Span-32" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-33">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-34">p</span><span class="MJXp-mo" id="MJXp-Span-35" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-36">v</span><span class="MJXp-mo" id="MJXp-Span-37" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-38">θ</span><span class="MJXp-mo" id="MJXp-Span-39" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-12">\log\ p(\boldsymbol{v};\boldsymbol{\theta})</script></span> nếu việc lấy xác suất biên biến <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-40"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-41">h</span></span></span><script type="math/tex" id="MathJax-Element-13">\boldsymbol{h}</script></span> quá tốn kém. Thay vào đó, ta có thể tính cận dưới <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-42"><span class="MJXp-mrow" id="MJXp-Span-43"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-44">L</span></span><span class="MJXp-mo" id="MJXp-Span-45" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-46">v</span><span class="MJXp-mo" id="MJXp-Span-47" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-48">θ</span><span class="MJXp-mo" id="MJXp-Span-49" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-50">q</span><span class="MJXp-mo" id="MJXp-Span-51" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-14">\mathcal{L} (\boldsymbol{v}, \boldsymbol{\theta}, q)</script></span> của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-52"><span class="MJXp-mi" id="MJXp-Span-53">log</span><span class="MJXp-mspace" id="MJXp-Span-54" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-55">p</span><span class="MJXp-mo" id="MJXp-Span-56" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-57">v</span><span class="MJXp-mo" id="MJXp-Span-58" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-59">θ</span><span class="MJXp-mo" id="MJXp-Span-60" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-15">\log\,p(\boldsymbol{v}; \boldsymbol{\theta})</script></span>. Cận này được gọi là <strong>cận dưới thực nghiệm (evidence lower bound)</strong> (ELBO). Hay còn gọi là <strong>năng lượng tự do biến phân âm (negative variational free energy)</strong>. Cụ thể, cận dưới thực nghiệm được xác định như sau<br>
<span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-61"><span class="MJXp-mtable" id="MJXp-Span-62"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-63" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-64" style="text-align: center;"><span class="MJXp-mrow" id="MJXp-Span-65"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-66">L</span></span><span class="MJXp-mo" id="MJXp-Span-67" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-68">v</span><span class="MJXp-mo" id="MJXp-Span-69" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-70">θ</span><span class="MJXp-mo" id="MJXp-Span-71" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-72">q</span><span class="MJXp-mo" id="MJXp-Span-73" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-74" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi" id="MJXp-Span-75">log</span><span class="MJXp-mspace" id="MJXp-Span-76" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-77">p</span><span class="MJXp-mo" id="MJXp-Span-78" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-79">v</span><span class="MJXp-mo" id="MJXp-Span-80" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-81">θ</span><span class="MJXp-mo" id="MJXp-Span-82" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-83" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-msubsup" id="MJXp-Span-84"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-85" style="margin-right: 0.05em;">D</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-86" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-87">K</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-88">L</span></span></span><span class="MJXp-mo" id="MJXp-Span-89" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-90">q</span><span class="MJXp-mo" id="MJXp-Span-91" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-92">h</span><span class="MJXp-mspace" id="MJXp-Span-93" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-94"><span class="MJXp-mo" id="MJXp-Span-95" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-96" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-97">v</span><span class="MJXp-mo" id="MJXp-Span-98" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mrow" id="MJXp-Span-99"><span class="MJXp-mo" id="MJXp-Span-100" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mrow" id="MJXp-Span-101"><span class="MJXp-mo" id="MJXp-Span-102" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-103">p</span><span class="MJXp-mo" id="MJXp-Span-104" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-105">h</span><span class="MJXp-mspace" id="MJXp-Span-106" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-107"><span class="MJXp-mo" id="MJXp-Span-108" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-109" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-110">v</span><span class="MJXp-mo" id="MJXp-Span-111" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-112">θ</span><span class="MJXp-mo" id="MJXp-Span-113" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-114" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-115" style="margin-left: 0em; margin-right: 0.222em;">,</span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-16">\mathcal{L} (\boldsymbol{v}, \boldsymbol{\theta},q)=\log\,p(\boldsymbol{v};\boldsymbol{\theta})-D_{KL}(q(\boldsymbol{h}\,|\, \boldsymbol{v} )||p(\boldsymbol{h}\,|\,\boldsymbol{v} ;\boldsymbol{\theta})),\tag{19.1} </script></span></p><p>trong đó <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-116"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117">q</span></span></span><script type="math/tex" id="MathJax-Element-17">q</script></span> là một phân phối xác suất tuỳ ý theo <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-118"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-119">h</span></span></span><script type="math/tex" id="MathJax-Element-18">\boldsymbol{h}</script></span>.</p><blockquote>
<p>DN: ELBO nên dịch là <code>Cận dưới thực nghiệm</code>. ELBO và variational lower bound là 1 đại lượng, nhưng chỉ khi nào dùng xấp xỉ biến phân người ta mới dùng từ variational lower bound, còn lại đều dùng ELBO. Thực tế thì gần như tất cả các tài liệu, kể cả khi đang nói về xấp xỉ biến phân cũng ghi là ELBO chứ ko ghi variational lower bound.</p>
</blockquote><p>Bởi vì sự khác biệt giữa <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-120"><span class="MJXp-mi" id="MJXp-Span-121">log</span><span class="MJXp-mspace" id="MJXp-Span-122" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-123">p</span><span class="MJXp-mo" id="MJXp-Span-124" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-125">v</span><span class="MJXp-mo" id="MJXp-Span-126" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-19">\log\,p(\boldsymbol{v})</script></span> và <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-127"><span class="MJXp-mrow" id="MJXp-Span-128"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-129">L</span></span><span class="MJXp-mo" id="MJXp-Span-130" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-131">v</span><span class="MJXp-mo" id="MJXp-Span-132" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-133">θ</span><span class="MJXp-mo" id="MJXp-Span-134" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-135">q</span><span class="MJXp-mo" id="MJXp-Span-136" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-20">\mathcal{L} (\boldsymbol{v}, \boldsymbol{\theta}, q)</script></span> được xác định bởi độ phân kỳ KL, và cũng vì độ phân kỳ KL này luôn không âm, ta có thể thấy rằng <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-137"><span class="MJXp-mrow" id="MJXp-Span-138"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-139">L</span></span></span></span><script type="math/tex" id="MathJax-Element-21">\mathcal{L}</script></span> luôn có giá trị nhỏ hơn hoặc bằng với xác xuất logarit kỳ vọng. Hai giá trị này bằng nhau khi và chỉ khi phân phối <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-140"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-141">q</span></span></span><script type="math/tex" id="MathJax-Element-22">q</script></span> giống với <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-142"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-143">p</span><span class="MJXp-mo" id="MJXp-Span-144" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-145">h</span><span class="MJXp-mspace" id="MJXp-Span-146" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-147"><span class="MJXp-mo" id="MJXp-Span-148" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-149" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-150">v</span><span class="MJXp-mo" id="MJXp-Span-151" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-23">p(\boldsymbol{h}\,|\,\boldsymbol{v})</script></span>.</p><p>Đáng ngạc nhiên, <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-152"><span class="MJXp-mrow" id="MJXp-Span-153"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-154">L</span></span></span></span><script type="math/tex" id="MathJax-Element-24">\mathcal{L}</script></span> có thể tính toán dễ dàng hơn đối với một số phân phối <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-155"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-156">q</span></span></span><script type="math/tex" id="MathJax-Element-25">q</script></span>. Bằng các phép biến đổi đại số đơn giản, ta có thể chuyển <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-157"><span class="MJXp-mrow" id="MJXp-Span-158"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-159">L</span></span></span></span><script type="math/tex" id="MathJax-Element-26">\mathcal{L}</script></span> thành dạng thuận tiện hơn nhiều:<br>
<span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-160"><span class="MJXp-mtable" id="MJXp-Span-161"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-162" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-163" style="text-align: center;"><span class="MJXp-mrow" id="MJXp-Span-164"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-165">L</span></span><span class="MJXp-mo" id="MJXp-Span-166" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-167">v</span><span class="MJXp-mo" id="MJXp-Span-168" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-169">θ</span><span class="MJXp-mo" id="MJXp-Span-170" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-171">q</span><span class="MJXp-mo" id="MJXp-Span-172" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-173" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi" id="MJXp-Span-174">log</span><span class="MJXp-mspace" id="MJXp-Span-175" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-176">p</span><span class="MJXp-mo" id="MJXp-Span-177" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-178">v</span><span class="MJXp-mo" id="MJXp-Span-179" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-180">θ</span><span class="MJXp-mo" id="MJXp-Span-181" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-182" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-msubsup" id="MJXp-Span-183"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-184" style="margin-right: 0.05em;">D</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-185" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-186">K</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-187">L</span></span></span><span class="MJXp-mo" id="MJXp-Span-188" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-189">q</span><span class="MJXp-mo" id="MJXp-Span-190" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-191">h</span><span class="MJXp-mspace" id="MJXp-Span-192" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-193"><span class="MJXp-mo" id="MJXp-Span-194" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-195" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-196">v</span><span class="MJXp-mo" id="MJXp-Span-197" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mrow" id="MJXp-Span-198"><span class="MJXp-mo" id="MJXp-Span-199" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mrow" id="MJXp-Span-200"><span class="MJXp-mo" id="MJXp-Span-201" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-202">p</span><span class="MJXp-mo" id="MJXp-Span-203" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-204">h</span><span class="MJXp-mspace" id="MJXp-Span-205" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-206"><span class="MJXp-mo" id="MJXp-Span-207" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-208" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-209">v</span><span class="MJXp-mo" id="MJXp-Span-210" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-211">θ</span><span class="MJXp-mo" id="MJXp-Span-212" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-213" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-27"> \mathcal{L} (\boldsymbol{v}, \boldsymbol{\theta}, q) = \log\, p(\boldsymbol{v}; \boldsymbol{\theta}) - D_{KL} (q(\boldsymbol{h}\,|\,\boldsymbol{v}) || p (\boldsymbol{h}\,|\,\boldsymbol{v} ; \boldsymbol{\theta})) \tag{19.2} </script></span></p><p><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-214"><span class="MJXp-mtable" id="MJXp-Span-215"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-216" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-217" style="text-align: center;"><span class="MJXp-mspace" id="MJXp-Span-218" style="width: 2em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-219" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi" id="MJXp-Span-220">log</span><span class="MJXp-mspace" id="MJXp-Span-221" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-222">p</span><span class="MJXp-mo" id="MJXp-Span-223" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-224">v</span><span class="MJXp-mo" id="MJXp-Span-225" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-226">θ</span><span class="MJXp-mo" id="MJXp-Span-227" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-228" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-msubsup" id="MJXp-Span-229"><span class="MJXp-mrow" id="MJXp-Span-230" style="margin-right: 0.05em;"><span class="MJXp-mi undefined" id="MJXp-Span-231">E</span></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-232" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-233">h</span><span class="MJXp-mo" id="MJXp-Span-234">∼</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-235">q</span></span></span><span class="MJXp-mi" id="MJXp-Span-236">log</span><span class="MJXp-mo" id="MJXp-Span-237" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mfrac" id="MJXp-Span-238" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-239">q</span><span class="MJXp-mo" id="MJXp-Span-240" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-241">h</span><span class="MJXp-mspace" id="MJXp-Span-242" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-243"><span class="MJXp-mo" id="MJXp-Span-244" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-245" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-246">v</span><span class="MJXp-mo" id="MJXp-Span-247" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-248">p</span><span class="MJXp-mo" id="MJXp-Span-249" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-250">h</span><span class="MJXp-mspace" id="MJXp-Span-251" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-252"><span class="MJXp-mo" id="MJXp-Span-253" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-254" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-255">v</span><span class="MJXp-mo" id="MJXp-Span-256" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-28"> \qquad = \log\,p(\boldsymbol{v};\boldsymbol{\theta}) - \mathbb{E}_{\boldsymbol{h}\sim q} \log\frac{q(\boldsymbol{h}\,|\,\boldsymbol{v})}{p(\boldsymbol{h}\,|\,\boldsymbol{v})}  \tag{19.3}</script></span></p><p><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-257"><span class="MJXp-mtable" id="MJXp-Span-258"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-259" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-260" style="text-align: center;"><span class="MJXp-mspace" id="MJXp-Span-261" style="width: 2em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-262" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi" id="MJXp-Span-263">log</span><span class="MJXp-mo" id="MJXp-Span-264" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-265">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-266">p</span><span class="MJXp-mo" id="MJXp-Span-267" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-268">v</span><span class="MJXp-mo" id="MJXp-Span-269" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-270">θ</span><span class="MJXp-mo" id="MJXp-Span-271" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-272" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-msubsup" id="MJXp-Span-273"><span class="MJXp-mrow" id="MJXp-Span-274" style="margin-right: 0.05em;"><span class="MJXp-mi undefined" id="MJXp-Span-275">E</span></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-276" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-277">h</span><span class="MJXp-mo" id="MJXp-Span-278">∼</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-279">q</span></span></span><span class="MJXp-mi" id="MJXp-Span-280">log</span><span class="MJXp-mo" id="MJXp-Span-281" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mfrac" id="MJXp-Span-282" style="vertical-align: 0.25em;"><span class="MJXp-box"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-283">q</span><span class="MJXp-mo" id="MJXp-Span-284" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-285">h</span><span class="MJXp-mspace" id="MJXp-Span-286" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-287"><span class="MJXp-mo" id="MJXp-Span-288" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-289" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-290">v</span><span class="MJXp-mo" id="MJXp-Span-291" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box"><span class="MJXp-mfrac" id="MJXp-Span-292" style="vertical-align: 0.25em;"><span class="MJXp-box MJXp-script"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-293">p</span><span class="MJXp-mo" id="MJXp-Span-294">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-295">h</span><span class="MJXp-mo" id="MJXp-Span-296">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-297">v</span><span class="MJXp-mo" id="MJXp-Span-298">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-299">θ</span><span class="MJXp-mo" id="MJXp-Span-300">)</span></span><span class="MJXp-box" style="margin-top: -0.9em;"><span class="MJXp-denom"><span><span class="MJXp-rule" style="height: 1em; border-top: none; border-bottom: 1px solid; margin: 0.1em 0px;"></span></span><span><span class="MJXp-box MJXp-script"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-301">p</span><span class="MJXp-mo" id="MJXp-Span-302">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-303">v</span><span class="MJXp-mo" id="MJXp-Span-304">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-305">θ</span><span class="MJXp-mo" id="MJXp-Span-306">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-29"> \qquad = \log \space p(\boldsymbol{v}; \boldsymbol{\theta}) - \mathbb{E}_{\boldsymbol{h}\sim q} \log\frac{q(\boldsymbol{h}\,|\,\boldsymbol{v})}{\frac{p (\boldsymbol{h},\boldsymbol{v} ; \boldsymbol{\theta})}{p (\boldsymbol{v} ; \boldsymbol{\theta})}} \tag{19.4}</script></span></p><p><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-307"><span class="MJXp-mtable" id="MJXp-Span-308"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-309" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-310" style="text-align: center;"><span class="MJXp-mspace" id="MJXp-Span-311" style="width: 2em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-312" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi" id="MJXp-Span-313">log</span><span class="MJXp-mo" id="MJXp-Span-314" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-315">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-316">p</span><span class="MJXp-mo" id="MJXp-Span-317" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-318">v</span><span class="MJXp-mo" id="MJXp-Span-319" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-320">θ</span><span class="MJXp-mo" id="MJXp-Span-321" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-322" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-msubsup" id="MJXp-Span-323"><span class="MJXp-mrow" id="MJXp-Span-324" style="margin-right: 0.05em;"><span class="MJXp-mi undefined" id="MJXp-Span-325">E</span></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-326" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-327">h</span><span class="MJXp-mo" id="MJXp-Span-328">∼</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-329">q</span></span></span><span class="MJXp-mo" id="MJXp-Span-330" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mi" id="MJXp-Span-331">log</span><span class="MJXp-mo" id="MJXp-Span-332" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-333">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-334">q</span><span class="MJXp-mo" id="MJXp-Span-335" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-336">h</span><span class="MJXp-mspace" id="MJXp-Span-337" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-338"><span class="MJXp-mo" id="MJXp-Span-339" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-340" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-341">v</span><span class="MJXp-mo" id="MJXp-Span-342" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-343" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi" id="MJXp-Span-344">log</span><span class="MJXp-mo" id="MJXp-Span-345" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-346">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-347">p</span><span class="MJXp-mo" id="MJXp-Span-348" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-349">h</span><span class="MJXp-mo" id="MJXp-Span-350" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-351">v</span><span class="MJXp-mo" id="MJXp-Span-352" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-353">θ</span><span class="MJXp-mo" id="MJXp-Span-354" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-355" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi" id="MJXp-Span-356">log</span><span class="MJXp-mo" id="MJXp-Span-357" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-358">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-359">p</span><span class="MJXp-mo" id="MJXp-Span-360" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-361">v</span><span class="MJXp-mo" id="MJXp-Span-362" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-363">θ</span><span class="MJXp-mo" id="MJXp-Span-364" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-365" style="margin-left: 0em; margin-right: 0em;">]</span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-30"> \qquad = \log \space p(\boldsymbol{v}; \boldsymbol{\theta}) - \mathbb{E}_{\boldsymbol{h}\sim q} [ \log \space q (\boldsymbol{h}\,|\,\boldsymbol{v}) - \log \space p (\boldsymbol{h},\boldsymbol{v}; \boldsymbol{\theta}) + \log \space p(\boldsymbol{v};\boldsymbol{\theta} ) ]  \tag{19.5}</script></span></p><p><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-366"><span class="MJXp-mtable" id="MJXp-Span-367"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-368" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-369" style="text-align: center;"><span class="MJXp-mspace" id="MJXp-Span-370" style="width: 2em; height: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-371" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mo" id="MJXp-Span-372" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-msubsup" id="MJXp-Span-373"><span class="MJXp-mrow" id="MJXp-Span-374" style="margin-right: 0.05em;"><span class="MJXp-mi undefined" id="MJXp-Span-375">E</span></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-376" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-377">h</span><span class="MJXp-mo" id="MJXp-Span-378">∼</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-379">q</span></span></span><span class="MJXp-mo" id="MJXp-Span-380" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mi" id="MJXp-Span-381">log</span><span class="MJXp-mo" id="MJXp-Span-382" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-383">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-384">q</span><span class="MJXp-mo" id="MJXp-Span-385" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-386">h</span><span class="MJXp-mspace" id="MJXp-Span-387" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-388"><span class="MJXp-mo" id="MJXp-Span-389" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-390" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-391">v</span><span class="MJXp-mo" id="MJXp-Span-392" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-393" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi" id="MJXp-Span-394">log</span><span class="MJXp-mo" id="MJXp-Span-395" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-396">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-397">p</span><span class="MJXp-mo" id="MJXp-Span-398" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-399">h</span><span class="MJXp-mo" id="MJXp-Span-400" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-401">v</span><span class="MJXp-mo" id="MJXp-Span-402" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-403">θ</span><span class="MJXp-mo" id="MJXp-Span-404" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-405" style="margin-left: 0em; margin-right: 0em;">]</span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-31"> \qquad = - \mathbb{E}_{\boldsymbol{h}\sim q} [ \log \space q (\boldsymbol{h}\,|\,\boldsymbol{v}) - \log \space p (\boldsymbol{h},\boldsymbol{v}; \boldsymbol{\theta}) ]  \tag{19.6}</script></span></p><p>Điều này dẫn đến một định nghĩa kinh điển hơn của cận dưới thực nghiệm,</p><p><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-406"><span class="MJXp-mtable" id="MJXp-Span-407"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-408" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-409" style="text-align: center;"><span class="MJXp-mrow" id="MJXp-Span-410"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-411">L</span></span><span class="MJXp-mo" id="MJXp-Span-412" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-413">v</span><span class="MJXp-mo" id="MJXp-Span-414" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-415">θ</span><span class="MJXp-mo" id="MJXp-Span-416" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-417">q</span><span class="MJXp-mo" id="MJXp-Span-418" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-419" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-420"><span class="MJXp-mrow" id="MJXp-Span-421" style="margin-right: 0.05em;"><span class="MJXp-mi undefined" id="MJXp-Span-422">E</span></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-423" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-424">h</span><span class="MJXp-mo" id="MJXp-Span-425">∼</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-426">q</span></span></span><span class="MJXp-mo" id="MJXp-Span-427" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mi" id="MJXp-Span-428">log</span><span class="MJXp-mo" id="MJXp-Span-429" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-430">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-431">q</span><span class="MJXp-mo" id="MJXp-Span-432" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-433">h</span><span class="MJXp-mo" id="MJXp-Span-434" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-435">v</span><span class="MJXp-mo" id="MJXp-Span-436" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-437" style="margin-left: 0em; margin-right: 0em;">]</span><span class="MJXp-mo" id="MJXp-Span-438" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-439">H</span><span class="MJXp-mo" id="MJXp-Span-440" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-441">q</span><span class="MJXp-mo" id="MJXp-Span-442" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-32"> \mathcal{L} (\boldsymbol{v}, \boldsymbol{\theta}, q ) = \mathbb{E}_{\boldsymbol{h}\sim q} [\log \space q (\boldsymbol{h},\boldsymbol{v})] + H(q) \tag{19.7} </script></span></p><blockquote>
<p><small><i class="fa fa-user"></i> Truong Thao Nguyen</small> Mình đã sửa <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-443"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-444">θ</span></span></span><script type="math/tex" id="MathJax-Element-33">\boldsymbol{\theta}</script></span> chứ không phải <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-445"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-446">θ</span></span></span><script type="math/tex" id="MathJax-Element-34">\theta</script></span>. Có thể còn nhiều chỗ tương tự</p>
</blockquote><p>Với một lựa chọn thích hợp của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-447"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-448">q</span></span></span><script type="math/tex" id="MathJax-Element-35">q</script></span>, <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-449"><span class="MJXp-mrow" id="MJXp-Span-450"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-451">L</span></span></span></span><script type="math/tex" id="MathJax-Element-36">\mathcal{L}</script></span> có thể dễ dàng tính toán được. Với bất kỳ sự lựa chọn nào của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-452"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-453">q</span></span></span><script type="math/tex" id="MathJax-Element-37">q</script></span>, <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-454"><span class="MJXp-mrow" id="MJXp-Span-455"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-456">L</span></span></span></span><script type="math/tex" id="MathJax-Element-38">\mathcal{L}</script></span> cung cấp một cận dưới của hàm hợp lý. Với <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-457"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-458">q</span><span class="MJXp-mo" id="MJXp-Span-459" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-460">h</span><span class="MJXp-mrow" id="MJXp-Span-461"><span class="MJXp-mo" id="MJXp-Span-462" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-463">v</span><span class="MJXp-mo" id="MJXp-Span-464" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-39">q (\boldsymbol{h} | \boldsymbol{v})</script></span> là xấp xỉ tốt hơn của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-465"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-466">p</span><span class="MJXp-mo" id="MJXp-Span-467" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-468">h</span><span class="MJXp-mspace" id="MJXp-Span-469" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-470"><span class="MJXp-mo" id="MJXp-Span-471" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-472" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-473">v</span><span class="MJXp-mo" id="MJXp-Span-474" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-40">p (\boldsymbol{h}\,|\, \boldsymbol{v})</script></span>, cận dưới <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-475"><span class="MJXp-mrow" id="MJXp-Span-476"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-477">L</span></span></span></span><script type="math/tex" id="MathJax-Element-41">\mathcal{L}</script></span> sẽ chặt hơn, hay nói cách khác, gần hơn với <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-478"><span class="MJXp-mi" id="MJXp-Span-479">log</span><span class="MJXp-mo" id="MJXp-Span-480" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-481">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-482">p</span><span class="MJXp-mo" id="MJXp-Span-483" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-484">v</span><span class="MJXp-mo" id="MJXp-Span-485" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-42">\log \space p (\boldsymbol{v})</script></span>. Khi <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-486"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-487">q</span><span class="MJXp-mo" id="MJXp-Span-488" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-489">h</span><span class="MJXp-mspace" id="MJXp-Span-490" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-491"><span class="MJXp-mo" id="MJXp-Span-492" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-493" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-494">v</span><span class="MJXp-mo" id="MJXp-Span-495" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-43">q (\boldsymbol{h}\,|\,\boldsymbol{v})</script></span> = <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-496"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-497">p</span><span class="MJXp-mo" id="MJXp-Span-498" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-499">h</span><span class="MJXp-mspace" id="MJXp-Span-500" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-501"><span class="MJXp-mo" id="MJXp-Span-502" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-503" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-504">v</span><span class="MJXp-mo" id="MJXp-Span-505" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-44">p (\boldsymbol{h}\,|\,\boldsymbol{v})</script></span>, xấp xỉ là hoàn hảo, và <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-506"><span class="MJXp-mrow" id="MJXp-Span-507"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-508">L</span></span><span class="MJXp-mo" id="MJXp-Span-509" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-510">v</span><span class="MJXp-mo" id="MJXp-Span-511" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-512">θ</span><span class="MJXp-mo" id="MJXp-Span-513" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-514">q</span><span class="MJXp-mo" id="MJXp-Span-515" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-516" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi" id="MJXp-Span-517">log</span><span class="MJXp-mo" id="MJXp-Span-518" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mtext" id="MJXp-Span-519">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-520">p</span><span class="MJXp-mo" id="MJXp-Span-521" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-522">v</span><span class="MJXp-mo" id="MJXp-Span-523" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-524">θ</span><span class="MJXp-mo" id="MJXp-Span-525" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-45">\mathcal{L} (\boldsymbol{v}, \boldsymbol{\theta}, q)=\log \space p (\boldsymbol{v}; \boldsymbol{\theta})</script></span></p><p>Chúng ta có thể hiểu rằng suy luận là quá trình tìm kiếm <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-526"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-527">q</span></span></span><script type="math/tex" id="MathJax-Element-46">q</script></span> để cực đại hoá <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-528"><span class="MJXp-mrow" id="MJXp-Span-529"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-530">L</span></span></span></span><script type="math/tex" id="MathJax-Element-47">\mathcal{L}</script></span>. suy luận chính xác cực đại hoá <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-531"><span class="MJXp-mrow" id="MJXp-Span-532"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-533">L</span></span></span></span><script type="math/tex" id="MathJax-Element-48">\mathcal{L}</script></span> một cách hoàn hảo bằng cách tìm kiếm trên một họ của hàm <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-534"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-535">q</span></span></span><script type="math/tex" id="MathJax-Element-49">q</script></span> mà có chứa <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-536"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-537">p</span><span class="MJXp-mo" id="MJXp-Span-538" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-539">h</span><span class="MJXp-mspace" id="MJXp-Span-540" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-541"><span class="MJXp-mo" id="MJXp-Span-542" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-543" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-544">v</span><span class="MJXp-mo" id="MJXp-Span-545" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-50">p (\boldsymbol{h}\,|\,\boldsymbol{v})</script></span>. Xuyên suốt chương này, chúng tôi sẽ chỉ ra làm cách nào để thu được các dạng khác nhau của suy luận xấp xỉ bằng cách áp dụng tối ưu xấp xỉ để tìm <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-546"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-547">q</span></span></span><script type="math/tex" id="MathJax-Element-51">q</script></span>. Chúng ta có thể làm cho quy trình tối ưu hóa ít tốn kém hơn nhưng vẫn xấp xỉ bằng cách giới hạn họ phân phối <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-548"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-549">q</span></span></span><script type="math/tex" id="MathJax-Element-52">q</script></span> mà việc tối ưu tìm kiếm được trên nó hoặc bằng cách sử dụng một quy trình tối ưu không hoàn hảo có thể không hoàn toàn cực đại hóa <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-550"><span class="MJXp-mrow" id="MJXp-Span-551"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-552">L</span></span></span></span><script type="math/tex" id="MathJax-Element-53">\mathcal{L}</script></span> nhưng có thể tăng nó lên đáng kể.</p><p>Cho dù chúng ta lựa chọn <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-553"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-554">q</span></span></span><script type="math/tex" id="MathJax-Element-54">q</script></span> nào, <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-555"><span class="MJXp-mrow" id="MJXp-Span-556"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-557">L</span></span></span></span><script type="math/tex" id="MathJax-Element-55">\mathcal{L}</script></span> vẫn là một cận dưới. Chúng ta có thể thu được cận dưới chặt chẽ hay lỏng lẻo hơn với chi phí tính toán thấp hay tốn kém hơn phụ thuộc vào cách tiếp cận bài toán tối ưu mà ta chọn. Chúng ta có thể thu được một phân phối <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-558"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-559">q</span></span></span><script type="math/tex" id="MathJax-Element-56">q</script></span> nghèo nàn nhưng giảm được chi phí tính toán bằng cách sử dụng một quy trình tối ưu hóa không hoàn hảo, hoặc bằng cách sử dụng một quy trình tối ưu hóa hoàn hảo trên một họ phân phối giới hạn của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-560"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-561">q</span></span></span><script type="math/tex" id="MathJax-Element-57">q</script></span>.</p><h2 id="192-Cực-đại-hoá-kỳ-vọng"><a class="anchor hidden-xs" href="#192-Cực-đại-hoá-kỳ-vọng" title="192-Cực-đại-hoá-kỳ-vọng"><span class="octicon octicon-link"></span></a>19.2 Cực đại hoá kỳ vọng</h2><p>Thuật toán đầu tiên mà chúng tôi giới thiệu dựa trên việc cực đại hóa một cận dưới <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-562"><span class="MJXp-mrow" id="MJXp-Span-563"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-564">L</span></span></span></span><script type="math/tex" id="MathJax-Element-58">\mathcal{L}</script></span> là thuật toán <strong>cực đại hóa kỳ vọng (expectation maximization)</strong> (EM), một thuật toán huấn luyện phổ biến cho các mô hình nhiều biến ẩn. Chúng tôi mô tả ở đây cái nhìn tổng quan về thuật toán EM được phát triển bởi Neal và Hinton (1999). Không giống như hầu hết các thuật toán khác được chúng tôi mô tả trong chương này, EM không phải là một phương pháp cho suy luận xấp xỉ, mà là phương pháp để học với một hậu nghiệm xấp xỉ.</p><p>Thuật toán EM chứa luân phiên nhau giữa hai bước cho đến khi hội tụ</p><p><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-565"><span class="MJXp-mspace" id="MJXp-Span-566" style="width: 2em; height: 0em;"></span></span></span><script type="math/tex" id="MathJax-Element-59">\qquad</script></span> <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-567"><span class="MJXp-mo" id="MJXp-Span-568" style="margin-left: 0.267em; margin-right: 0.267em;">∙</span></span></span><script type="math/tex" id="MathJax-Element-60">\bullet</script></span>  <strong>Bước E</strong> (bước kỳ vọng): Ký hiệu <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-569"><span class="MJXp-msubsup" id="MJXp-Span-570"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-571" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-572" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-573">(</span><span class="MJXp-mn" id="MJXp-Span-574">0</span><span class="MJXp-mo" id="MJXp-Span-575">)</span></span></span></span></span><script type="math/tex" id="MathJax-Element-61">\boldsymbol{\theta}^{(0)}</script></span> là giá trị của các tham số tại thời điểm bắt đầu của bước. Đặt <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-576"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-577">q</span><span class="MJXp-mo" id="MJXp-Span-578" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-579"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-580" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-581" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-582">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-583">i</span><span class="MJXp-mo" id="MJXp-Span-584">)</span></span></span><span class="MJXp-mrow" id="MJXp-Span-585"><span class="MJXp-mo" id="MJXp-Span-586" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-587">v</span><span class="MJXp-mo" id="MJXp-Span-588" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-62">q (\boldsymbol{h}^{(i)} | \boldsymbol{v})</script></span> = <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-589"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-590">p</span><span class="MJXp-mo" id="MJXp-Span-591" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-592"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-593" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-594" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-595">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-596">i</span><span class="MJXp-mo" id="MJXp-Span-597">)</span></span></span><span class="MJXp-mrow" id="MJXp-Span-598"><span class="MJXp-mo" id="MJXp-Span-599" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-msubsup" id="MJXp-Span-600"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-601" style="margin-right: 0.05em;">v</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-602" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-603">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-604">i</span><span class="MJXp-mo" id="MJXp-Span-605">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-606" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-msubsup" id="MJXp-Span-607"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-608" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-609" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-610">(</span><span class="MJXp-mn" id="MJXp-Span-611">0</span><span class="MJXp-mo" id="MJXp-Span-612">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-613" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-63">p (\boldsymbol{h}^{(i)} | \boldsymbol{v}^{(i)}; \boldsymbol{\theta}^{(0)})</script></span> cho tất cả các chỉ số <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-614"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-615">i</span></span></span><script type="math/tex" id="MathJax-Element-64">i</script></span> của các mẫu huấn luyện <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-616"><span class="MJXp-msubsup" id="MJXp-Span-617"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-618" style="margin-right: 0.05em;">v</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-619" style="vertical-align: 0.5em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-620">i</span></span></span></span></span><script type="math/tex" id="MathJax-Element-65">\boldsymbol{v}^{i}</script></span> mà chúng ta muốn huấn luyện (các biến thể lô và lô nhỏ đều hợp lệ). Có nghĩa là <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-621"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-622">q</span></span></span><script type="math/tex" id="MathJax-Element-66">q</script></span> được xác định theo giá trị tham số <em>hiện tại</em> của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-623"><span class="MJXp-msubsup" id="MJXp-Span-624"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-625" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-626" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-627">(</span><span class="MJXp-mn" id="MJXp-Span-628">0</span><span class="MJXp-mo" id="MJXp-Span-629">)</span></span></span></span></span><script type="math/tex" id="MathJax-Element-67">\boldsymbol{\theta}^{(0)}</script></span>; nếu chúng ta thay đổi <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-630"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-631">θ</span></span></span><script type="math/tex" id="MathJax-Element-68">\boldsymbol{\theta}</script></span>, thì <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-632"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-633">p</span><span class="MJXp-mo" id="MJXp-Span-634" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-635">h</span><span class="MJXp-mo" id="MJXp-Span-636" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-637">v</span><span class="MJXp-mrow" id="MJXp-Span-638"><span class="MJXp-mo" id="MJXp-Span-639" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-640">θ</span><span class="MJXp-mo" id="MJXp-Span-641" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-69">p (\boldsymbol{h},\boldsymbol{v}| \boldsymbol{\theta})</script></span> sẽ thay đổi, nhưng <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-642"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-643">q</span><span class="MJXp-mo" id="MJXp-Span-644" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-645">h</span><span class="MJXp-mrow" id="MJXp-Span-646"><span class="MJXp-mo" id="MJXp-Span-647" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-648">v</span><span class="MJXp-mo" id="MJXp-Span-649" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-70">q ( \boldsymbol{h} | \boldsymbol{v})</script></span> sẽ vẫn bằng <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-650"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-651">p</span><span class="MJXp-mo" id="MJXp-Span-652" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-653">h</span><span class="MJXp-mrow" id="MJXp-Span-654"><span class="MJXp-mo" id="MJXp-Span-655" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-656">v</span><span class="MJXp-mo" id="MJXp-Span-657" style="margin-left: 0em; margin-right: 0.222em;">;</span><span class="MJXp-msubsup" id="MJXp-Span-658"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-659" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-660" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-661">(</span><span class="MJXp-mn" id="MJXp-Span-662">0</span><span class="MJXp-mo" id="MJXp-Span-663">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-664" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-71">p (\boldsymbol{h}|\boldsymbol{v}; \boldsymbol{\theta}^{(0)})</script></span></p><p><span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-665"><span class="MJXp-mspace" id="MJXp-Span-666" style="width: 2em; height: 0em;"></span></span></span><script type="math/tex" id="MathJax-Element-72">\qquad</script></span> <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-667"><span class="MJXp-mo" id="MJXp-Span-668" style="margin-left: 0.267em; margin-right: 0.267em;">∙</span></span></span><script type="math/tex" id="MathJax-Element-73">\bullet</script></span> <strong>Bước M</strong>  (bước cực đại hóa): Cực đại hoá hoàn toàn hoặc một phần<br>
<span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-669"><span class="MJXp-mtable" id="MJXp-Span-670"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-671" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-672" style="text-align: center;"><span class="MJXp-munderover" id="MJXp-Span-673"><span><span class="MJXp-mo" id="MJXp-Span-674" style="margin-left: 0.111em; margin-right: 0.167em;"><span class="MJXp-largeop">∑</span></span></span><span class="MJXp-script"><span class="MJXp-mrow" id="MJXp-Span-675" style="margin-left: 0px;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-676">i</span></span></span></span><span class="MJXp-mtext" id="MJXp-Span-677">&nbsp;</span><span class="MJXp-mrow" id="MJXp-Span-678"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-679">L</span></span><span class="MJXp-mo" id="MJXp-Span-680" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-681"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-682" style="margin-right: 0.05em;">v</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-683" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-684">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-685">i</span><span class="MJXp-mo" id="MJXp-Span-686">)</span></span></span><span class="MJXp-mo" id="MJXp-Span-687" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-688">θ</span><span class="MJXp-mo" id="MJXp-Span-689" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-690">q</span><span class="MJXp-mo" id="MJXp-Span-691" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-692" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-74">\sum\limits_{i} \space \mathcal{L} (\boldsymbol{v}^{(i)} ,\boldsymbol{\theta}, q)  \tag{19.8})</script></span><br>
theo <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-693"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-694">θ</span></span></span><script type="math/tex" id="MathJax-Element-75">\boldsymbol{\theta}</script></span> sử dụng thuật toán tối ưu được lựa chọn.</p><p>Điều này có thể được xem như là một thuật toán tăng trưởng theo tọa độ để cực đại hóa <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-695"><span class="MJXp-mrow" id="MJXp-Span-696"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-697">L</span></span></span></span><script type="math/tex" id="MathJax-Element-76">\mathcal{L}</script></span>. Trong một bước của giải thuật, chúng ta cực đại hóa <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-698"><span class="MJXp-mrow" id="MJXp-Span-699"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-700">L</span></span></span></span><script type="math/tex" id="MathJax-Element-77">\mathcal{L}</script></span> theo <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-701"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-702">q</span></span></span><script type="math/tex" id="MathJax-Element-78">q</script></span>, và bước khác, chúng ta cực đại hóa <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-703"><span class="MJXp-mrow" id="MJXp-Span-704"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-705">L</span></span></span></span><script type="math/tex" id="MathJax-Element-79">\mathcal{L}</script></span> theo <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-706"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-707">θ</span></span></span><script type="math/tex" id="MathJax-Element-80">\boldsymbol{\theta}</script></span>.</p><p>Gradient ngẫu nhiên tăng trường trên các mô hình chứa biến ẩn có thể xem như là một trường hợp đặc biệt của thuật toán EM, ở đó bước M bao gồm một bước gradient đơn. Các biến thể khác của thuật toán EM có thể tạo ra nhiều bước lớn hơn. Đối với một vài họ mô hình, bước M thậm chí có thể được thực hiện một cách giải tích, nhảy trực tiếp đến lời giải tối ưu cho <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-708"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-709">θ</span></span></span><script type="math/tex" id="MathJax-Element-81">\boldsymbol{\theta}</script></span> với <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-710"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-711">q</span></span></span><script type="math/tex" id="MathJax-Element-82">q</script></span> hiện tại.</p><p>Mặc dù bước E bao hàm suy luận chính xác, chúng ta có hiểu thuật toán EM sử dụng suy luận xấp xỉ theo một nghĩa nào đó. Cụ thể, bước M giả định rằng cùng một giá trị của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-712"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-713">q</span></span></span><script type="math/tex" id="MathJax-Element-83">q</script></span> có thể được dùng cho tất cả các giá trị của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-714"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-715">θ</span></span></span><script type="math/tex" id="MathJax-Element-84">\boldsymbol{\theta}</script></span>. Điều này sẽ tạo ra khoảng cách giữa <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-716"><span class="MJXp-mrow" id="MJXp-Span-717"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-718">L</span></span></span></span><script type="math/tex" id="MathJax-Element-85">\mathcal{L}</script></span> và giá trị thực của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-719"><span class="MJXp-mi" id="MJXp-Span-720">log</span><span class="MJXp-mo" id="MJXp-Span-721" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-722">p</span><span class="MJXp-mo" id="MJXp-Span-723" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-724">v</span><span class="MJXp-mo" id="MJXp-Span-725" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-86">\log p(\boldsymbol{v})</script></span> khi bước M càng lúc càng dịch chuyển ra xa khỏi giá trị <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-726"><span class="MJXp-msubsup" id="MJXp-Span-727"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-728" style="margin-right: 0.05em;">θ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-729" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-730">(</span><span class="MJXp-mn" id="MJXp-Span-731">0</span><span class="MJXp-mo" id="MJXp-Span-732">)</span></span></span></span></span><script type="math/tex" id="MathJax-Element-87">\boldsymbol{\theta}^{(0)}</script></span> được sử dụng trong bước E. May mắn thay, bước E lại giảm khoảng cách này về 0 trước khi ta vào vòng lặp lần tiếp theo.</p><p>Thuật toán EM chứa một vài cách nhìn khác nhau. Đầu tiên là cấu trúc cơ bản của quá trình học, trong đó chúng ta cập nhật tham số mô hình để cải thiện hàm hợp lý của một tập dữ liệu hoàn chỉnh, nơi mà các biến khuyết sẽ được cung cấp giá trị bằng một ước lượng của phân phối hậu nghiệm. Cách nhìn này không phải là duy nhất cho thuật toán EM. Ví dụ, sử dụng trượt gradient để cực đại hoá logarit hàm hợp lý cũng có cùng thuộc tính này; việc tính toán gradient của logarit hàm hợp lý đòi hỏi tính toán các kỳ vọng theo phân phối hậu nghiệm trên các đơn vị ẩn. Một cách nhìn then chốt khác trong thuật toán EM là chúng ta có thể tiếp tục sử dụng một giá trị <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-733"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-734">q</span></span></span><script type="math/tex" id="MathJax-Element-88">q</script></span> ngay cả sau khi đã chuyển sang một giá trị khác của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-735"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-736">θ</span></span></span><script type="math/tex" id="MathJax-Element-89">\boldsymbol{\theta}</script></span>. Cách nhìn này được sử dụng xuyên suốt học máy cổ điển để tính các cập nhật lớn của bước M. Trong ngữ cảnh học sâu, hầu hết các mô hình quá phức tạp để chấp nhận một giải pháp dễ tính toán cho một cập nhật tối ưu của bước M lớn, vậy nên cách nhìn thứ hai này, độc nhất cho thuật toán EM, hiếm khi được sử dụng.</p><h1 id="193-Suy-luận-MAP-và-mã-hoá-thưa"><a class="anchor hidden-xs" href="#193-Suy-luận-MAP-và-mã-hoá-thưa" title="193-Suy-luận-MAP-và-mã-hoá-thưa"><span class="octicon octicon-link"></span></a>19.3 Suy luận MAP và mã hoá thưa</h1><p>Ta thường dùng thuật ngữ <em>suy luận</em> để tham chiếu đến việc tính toán phân phối xác suất của một tập các biến khi đã biết một tập các biến khác. Khi huấn luyện mô hình xác suất với các biến ẩn, ta thường quan tâm đến việc tính <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-737"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-738">p</span><span class="MJXp-mo" id="MJXp-Span-739" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-740">h</span><span class="MJXp-mspace" id="MJXp-Span-741" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mrow" id="MJXp-Span-742"><span class="MJXp-mo" id="MJXp-Span-743" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mspace" id="MJXp-Span-744" style="width: 0.167em; height: 0em;"></span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-745">v</span><span class="MJXp-mo" id="MJXp-Span-746" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-90">p(\boldsymbol{h}\,|\,\boldsymbol{v})</script></span>. Một dạng thay thế khác của phép suy luận là tính toán đơn trị hợp lý nhất của các biến khuyết, hơn là luận ra toàn bộ phân phối của các giá trị khả dĩ của chúng.</p><p>— trung đang làm việc tại đây ----</p><p>-----  Tiên đang dịch tu trang 634 ------</p><p>Trong ngữ cảnh các mô hình có biến ẩn, nó có nghĩa rằng ta cần tính<br>
<span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-747"><span class="MJXp-mtable" id="MJXp-Span-748"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-749" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-750" style="text-align: center;"><span class="MJXp-msubsup" id="MJXp-Span-751"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-752" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-753" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-754">∗</span></span></span><span class="MJXp-mo" id="MJXp-Span-755" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-munder" id="MJXp-Span-756"><span><span class="MJXp-mtext" id="MJXp-Span-757">arg max</span></span><span class="MJXp-script"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-758" style="margin-left: 0px;">h</span></span></span><span class="MJXp-mtext" id="MJXp-Span-759">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-760">p</span><span class="MJXp-mo" id="MJXp-Span-761" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-762">h</span><span class="MJXp-mtext" id="MJXp-Span-763">&nbsp;</span><span class="MJXp-mrow" id="MJXp-Span-764"><span class="MJXp-mo" id="MJXp-Span-765" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mtext" id="MJXp-Span-766">&nbsp;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-767">v</span><span class="MJXp-mo" id="MJXp-Span-768" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-769" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-91">\boldsymbol{h}^{*} = \underset{\boldsymbol{h}}{\text{arg max}} \space p(\boldsymbol{h}\space|\space\boldsymbol{v}). \tag{19.9}</script></span></p><p>Phép toán trên được biết đến là suy luận <strong>hậu nghiệm cực đại</strong>, viết tắt là suy luận MAP.</p><p>Suy luận MAP thường không được xem là phép suy luận xấp xỉ - bởi vì nó tính chính xác giá trị hợp lý nhất của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-770"><span class="MJXp-msubsup" id="MJXp-Span-771"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-772" style="margin-right: 0.05em;">h</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-773" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-774">∗</span></span></span></span></span><script type="math/tex" id="MathJax-Element-92">\boldsymbol{h}^{*}</script></span>. Tuy nhiên, nếu như chúng ta muốn phát triển một quy trình học dựa trên cực đại hóa <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-775"><span class="MJXp-mrow" id="MJXp-Span-776"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-777">L</span></span><span class="MJXp-mo" id="MJXp-Span-778" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-779">v</span><span class="MJXp-mo" id="MJXp-Span-780" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-781">h</span><span class="MJXp-mo" id="MJXp-Span-782" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-783">q</span><span class="MJXp-mo" id="MJXp-Span-784" style="margin-left: 0em; margin-right: 0em;">)</span></span></span><script type="math/tex" id="MathJax-Element-93">\mathcal{L}(\boldsymbol{v}, \boldsymbol{h}, q)</script></span>, ta có thể xem suy luận MAP là một quy trình để tính giá trị của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-785"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-786">q</span></span></span><script type="math/tex" id="MathJax-Element-94">q</script></span>. Với cách diễn dịch này, chúng ta có thể xem suy luận MAP như phép suy luận xấp xỉ, bởi vì suy luận MAP bây giờ không cung cấp giá trị <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-787"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-788">q</span></span></span><script type="math/tex" id="MathJax-Element-95">q</script></span> tối ưu.</p><p>Quay lại với công thức 19.1, suy luận chính xác bao gồm việc cực đại hóa<br>
<span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-789"><span class="MJXp-mtable" id="MJXp-Span-790"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-791" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-792" style="text-align: center;"><span class="MJXp-mrow" id="MJXp-Span-793"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-794">L</span></span><span class="MJXp-mo" id="MJXp-Span-795" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-796">v</span><span class="MJXp-mo" id="MJXp-Span-797" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-798">θ</span><span class="MJXp-mo" id="MJXp-Span-799" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-800">q</span><span class="MJXp-mo" id="MJXp-Span-801" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-802" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-msubsup" id="MJXp-Span-803"><span class="MJXp-mrow" id="MJXp-Span-804" style="margin-right: 0.05em;"><span class="MJXp-mi undefined" id="MJXp-Span-805">E</span></span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-806" style="vertical-align: -0.4em;"><span class="MJXp-mrow" id="MJXp-Span-807"><span class="MJXp-mi MJXp-bold" id="MJXp-Span-808">h</span></span><span class="MJXp-mo" id="MJXp-Span-809">∼</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-810">q</span></span></span><span class="MJXp-mo" id="MJXp-Span-811" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mi" id="MJXp-Span-812">log</span><span class="MJXp-mo" id="MJXp-Span-813" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-814">p</span><span class="MJXp-mo" id="MJXp-Span-815" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-816">h</span><span class="MJXp-mo" id="MJXp-Span-817" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-818">v</span><span class="MJXp-mo" id="MJXp-Span-819" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-820" style="margin-left: 0em; margin-right: 0em;">]</span><span class="MJXp-mo" id="MJXp-Span-821" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-822">H</span><span class="MJXp-mo" id="MJXp-Span-823" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-824">q</span><span class="MJXp-mo" id="MJXp-Span-825" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-96"> \mathcal{L}(\boldsymbol{v}, \boldsymbol{\theta}, q) = \mathbb{E}_{\mathbf{h} \sim q} [\log p(\boldsymbol{h}, \boldsymbol{v})] + H(q) \tag{19.10} </script></span></p><p>đối với <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-826"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-827">q</span></span></span><script type="math/tex" id="MathJax-Element-97">q</script></span> trên một họ phân phối xác suất không ràng buộc, sử dụng một thuật toán tối ưu chính xác. Chúng ta có thể biến đổi suy luận MAP trở thành một dạng suy luận xấp xỉ bằng cách ràng buộc họ phân phối của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-828"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-829">q</span></span></span><script type="math/tex" id="MathJax-Element-98">q</script></span>. Cụ thể, ta quy định rằng <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-830"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-831">q</span></span></span><script type="math/tex" id="MathJax-Element-99">q</script></span> là một phân phối Dirac:<br>
<span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-832"><span class="MJXp-mtable" id="MJXp-Span-833"><span><span class="MJXp-mlabeledtr" id="MJXp-Span-834" style="vertical-align: baseline;"><span class="MJXp-mtd" id="MJXp-Span-835" style="text-align: center;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-836">q</span><span class="MJXp-mo" id="MJXp-Span-837" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-838">h</span><span class="MJXp-mtext" id="MJXp-Span-839">&nbsp;</span><span class="MJXp-mrow" id="MJXp-Span-840"><span class="MJXp-mo" id="MJXp-Span-841" style="margin-left: 0.167em; margin-right: 0.167em;">|</span></span><span class="MJXp-mtext" id="MJXp-Span-842">&nbsp;</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-843">v</span><span class="MJXp-mo" id="MJXp-Span-844" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-845" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-846">δ</span><span class="MJXp-mo" id="MJXp-Span-847" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-848">h</span><span class="MJXp-mo" id="MJXp-Span-849" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-850">μ</span><span class="MJXp-mo" id="MJXp-Span-851" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-852" style="margin-left: 0em; margin-right: 0.222em;">.</span></span></span></span></span></span></span><script type="math/tex; mode=display" id="MathJax-Element-100">q(\boldsymbol{h\space |\space v}) = \delta(\boldsymbol{h} - \boldsymbol{\mu}).\tag{19.11}</script></span></p><blockquote>
<p>Xin phép đổi từ “hạn chế” của anh Duy thành từ “ràng buộc”.</p>
</blockquote><p>Bằng cách này, chúng ta có thể kiểm soát <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-853"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-854">q</span></span></span><script type="math/tex" id="MathJax-Element-101">q</script></span> một cách trọn vẹn thông qua <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-855"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-856">μ</span></span></span><script type="math/tex" id="MathJax-Element-102">\boldsymbol{\mu}</script></span>. Khi bỏ các biểu thức của <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-857"><span class="MJXp-mrow" id="MJXp-Span-858"><span class="MJXp-mi MJXp-cal" id="MJXp-Span-859">L</span></span></span></span><script type="math/tex" id="MathJax-Element-103">\mathcal{L}</script></span> không thay đổi theo <span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-860"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-861">μ</span></span></span><script type="math/tex" id="MathJax-Element-104">\boldsymbol{\mu}</script></span>, ta có bài toán tối ưu<br>
<span class="mathjax"><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-862"><span class="MJXp-mtable" id="MJXp-Span-863"><span class="MJXp-mlabeledtr" id="MJXp-Span-864"><span class="MJXp-mtd" id="MJXp-Span-865"><span class="MJXp-msubsup" id="MJXp-Span-866"><span class="MJXp-mi MJXp-bold MJXp-italic" id="MJXp-Span-867" style="margin-right: 0.05em;">μ</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-868" style="vertical-align: 0.5em;"><span class="MJXp-mo" id="MJXp-Span-869">∗</span></span></span><span class="MJXp-mo" id="MJXp-Span-870" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-munder" id="MJXp-Span-871"><span><span class="MJXp-mi" id="MJXp-Span-872">arg</span><span class="MJXp-mo" id="MJXp-Span-873" style="margin-left: 0em; margin-right: 0em;"></span><span class="MJXp-mo" id="MJXp-Span-874">max</span></span></span></span></span></span></span></span><script type="math/tex; mode=display">\boldsymbol{\mu}^{*} = \underset{\boldsymbol{\mu}}{\arg \max} \log p(\boldsymbol{h\space |\space v}), \tag{19.12} </script></span></p><p>mà nó tương đương với bài toán suy luận MAP<br>
<span class="mathjax"><span class="MathJax_Preview"> \boldsymbol{h}^{*} = \underset{\boldsymbol{h}}{\arg\max} \space p(\boldsymbol{h\space |\space v}). \tag{19.13}</span><script type="math/tex; mode=display"> \boldsymbol{h}^{*} = \underset{\boldsymbol{h}}{\arg\max} \space p(\boldsymbol{h\space |\space v}). \tag{19.13}</script></span></p><p>Do đó, chúng ta có thể chứng minh rằng đây là một quy trình học tương tự với thuật toán EM, trong đó ta luân phiên giữa việc thực hiện phép suy luận MAP để suy ra <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}^{*}</span><script type="math/tex">\boldsymbol{h}^{*}</script></span> và sau đó cập nhật <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta}</span><script type="math/tex">\boldsymbol{\theta}</script></span> để tăng giá trị của <span class="mathjax"><span class="MathJax_Preview">\log p\boldsymbol{(h^{*}, v)}</span><script type="math/tex">\log p\boldsymbol{(h^{*}, v)}</script></span>. Giống như đối với thuật toán EM, đây là một dạng thuật toán tăng trưởng theo tọa độ trên <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span>, trong đó chúng ta luân phiên giữa việc dùng suy luận để tối ưu <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> theo <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> và việc cập nhật tham số để tối ưu <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> theo <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta}</span><script type="math/tex">\boldsymbol{\theta}</script></span>. Toàn bộ quy trình này có thể được chứng minh tính đúng đắn vì <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> là một cận dưới của <span class="mathjax"><span class="MathJax_Preview">\log p(\boldsymbol{v})</span><script type="math/tex">\log p(\boldsymbol{v})</script></span>. Trong trường hợp của suy luận MAP, lý luận này khá ngây ngô bởi vì cận của <span class="mathjax"><span class="MathJax_Preview">\log p(\boldsymbol{v})</span><script type="math/tex">\log p(\boldsymbol{v})</script></span> vô cùng lỏng lẻo, do entropy khả vi của phân phối Dirac là âm vô cùng. Đối với trường hợp này, thêm nhiễu vào <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\mu}</span><script type="math/tex">\boldsymbol{\mu}</script></span> sẽ làm cận có ý nghĩa trở lại.</p><p>Suy luận MAP thường được dùng như là một bộ trích xuất đặc trưng hoặc là một cơ chế học trong học sâu. Nó được dùng chủ yếu cho các mô hình mã hoá thưa.</p><p>Như đã nói ở mục 13.4, mã hoá thưa là một mô hình nhân tố tuyến tính áp đặt một tiên nghiệm có khả năng gây ra sự thưa lên những đơn vị ẩn của nó. Một lựa chọn phổ biến là tiên nghiệm giai thừa Laplace, với</p><p><span class="mathjax"><span class="MathJax_Preview"> p(h_i) = \frac{\lambda}{2}e^{-\lambda|h_i|} \tag{19.14}</span><script type="math/tex; mode=display"> p(h_i) = \frac{\lambda}{2}e^{-\lambda|h_i|} \tag{19.14}</script></span></p><p>Những đơn vị khả kiến khi đó được sinh ra bằng cách thực hiện một phép biến đổi tuyến tính và thêm vào nhiễu:<br>
<span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{x\space|\space h}) = \mathcal{N}(\boldsymbol{v}; \boldsymbol{Wh + b}, \beta^{-1}\boldsymbol{I}). \tag{19.15}</span><script type="math/tex; mode=display">p(\boldsymbol{x\space|\space h}) = \mathcal{N}(\boldsymbol{v}; \boldsymbol{Wh + b}, \beta^{-1}\boldsymbol{I}). \tag{19.15}</script></span></p><p>Việc tính toán hoặc thậm chí biểu diễn <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h\space|\space v})</span><script type="math/tex">p(\boldsymbol{h\space|\space v})</script></span> là khó khăn. Mỗi cặp biến <span class="mathjax"><span class="MathJax_Preview">h_i</span><script type="math/tex">h_i</script></span> và <span class="mathjax"><span class="MathJax_Preview">h_j</span><script type="math/tex">h_j</script></span> đều là nút cha của <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span>. Điều đó có nghĩa là khi chúng ta quan sát được giá trị của <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span>, mô hình đồ thị có một đường đi kết nối <span class="mathjax"><span class="MathJax_Preview">h_i</span><script type="math/tex">h_i</script></span> và <span class="mathjax"><span class="MathJax_Preview">h_j</span><script type="math/tex">h_j</script></span>. Tất cả những biến ẩn do đó đều tham gia vào một bè rất lớn trong <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h\space|\space v})</span><script type="math/tex">p(\boldsymbol{h\space|\space v})</script></span>. Nếu mô hình là Gauss, thì tất cả những tương tác này có thể được mô hình hoá một cách hiệu quả thông qua ma trận hiệp phương sai, nhưng tiên nghiệm thưa sẽ làm cho những tương tác này không còn là Gauss nữa.</p><p>Vì <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h\space|\space v})</span><script type="math/tex">p(\boldsymbol{h\space|\space v})</script></span> khó tính toán, việc tính toán logarit hàm hợp lý và gradient của nó cũng gặp vấn đề như vậy. Do đó ta không thể sử dụng học hợp lý cực đại chính xác. Thay vào đó, chúng ta dùng suy luận MAP và học các tham số bằng cách cực đại hóa ELBO được định nghĩa bởi phân phối Dirac xung quanh ước lượng MAP của <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span>.</p><p>Nếu chúng ta gộp các vector <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> trong tập huấn luyện thành một ma trận <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{H}</span><script type="math/tex">\boldsymbol{H}</script></span>, và gộp tất cả các vector <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span> thành một ma trận <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{V}</span><script type="math/tex">\boldsymbol{V}</script></span>, thì quy trình học mã hoá thưa bao gồm việc cực tiểu hóa<br>
<span class="mathjax"><span class="MathJax_Preview"> J(\boldsymbol{H, W})= \sum_{i, j} |H_{i,j}|+ \sum_{i, j}
(\boldsymbol{V} - \boldsymbol{HW}^{\top})^{2}_{i, j}. \tag{19.16} </span><script type="math/tex; mode=display"> J(\boldsymbol{H, W})= \sum_{i, j} |H_{i,j}|+ \sum_{i, j}
(\boldsymbol{V} - \boldsymbol{HW}^{\top})^{2}_{i, j}. \tag{19.16} </script></span></p><p>Hầu như tất cả ứng dụng của mã hoá thưa đều bao gồm suy giảm trọng số hoặc một ràng buộc trên các chuẩn của các cột trong ma trận <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{W}</span><script type="math/tex">\boldsymbol{W}</script></span>, để ngăn ngừa lời giải bất ổn khi <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{H}</span><script type="math/tex">\boldsymbol{H}</script></span> cực nhỏ và <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{W}</span><script type="math/tex">\boldsymbol{W}</script></span> cực lớn.</p><p>Chúng ta có thể cực tiểu hoá <span class="mathjax"><span class="MathJax_Preview">J</span><script type="math/tex">J</script></span> bằng cách luân phiên giữa việc cực tiểu hoá theo <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{H}</span><script type="math/tex">\boldsymbol{H}</script></span> và cực tiểu hoá theo <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{W}</span><script type="math/tex">\boldsymbol{W}</script></span>. Cả hai bài toán phụ ở trên đều lồi. Trong thực tế, cực tiểu hoá theo <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{W}</span><script type="math/tex">\boldsymbol{W}</script></span> chỉ là bài toán hồi quy tuyến tính. Tuy nhiên, cực tiểu hoá <span class="mathjax"><span class="MathJax_Preview">J</span><script type="math/tex">J</script></span> theo cả hai đối số thường không phải là bài toán lồi.</p><p>Để cực tiểu hoá theo <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{H}</span><script type="math/tex">\boldsymbol{H}</script></span> cần có những thuật toán đặc biệt như thuật toán tìm kiếm dấu đặc trưng (Lee và cộng sự, 2007).</p><h2 id="194-Suy-luận-biến-phân-và-học-biến-phân"><a class="anchor hidden-xs" href="#194-Suy-luận-biến-phân-và-học-biến-phân" title="194-Suy-luận-biến-phân-và-học-biến-phân"><span class="octicon octicon-link"></span></a>19.4 Suy luận biến phân và học biến phân</h2><p>Chúng ta đã thấy làm thế nào mà cận dưới thực nghiệm <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}(\boldsymbol{v}, \boldsymbol{\theta}, q)</span><script type="math/tex">\mathcal{L}(\boldsymbol{v}, \boldsymbol{\theta}, q)</script></span> là một cận dưới của <span class="mathjax"><span class="MathJax_Preview">\log p(\boldsymbol{v};\boldsymbol {\theta})</span><script type="math/tex">\log p(\boldsymbol{v};\boldsymbol {\theta})</script></span>, và làm thế nào mà suy luận có thể được xem như cực đại hoá <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> theo <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>, và quá trình học được xem như cực đại hoá <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> theo <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta}</span><script type="math/tex">\boldsymbol{\theta}</script></span>. Chúng ta cũng đã thấy rằng thuật toán EM cho phép chúng ta thực hiện các bước học lớn với <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> cố định và những thuật toán học dựa vào suy luận MAP cho phép chúng ta học nhờ vào một ước lượng điểm của <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h\space|\space v})</span><script type="math/tex">p(\boldsymbol{h\space|\space v})</script></span> hơn là suy luận ra toàn bộ phân phối. Bây giờ, chúng ta sẽ đưa ra một phương pháp tổng quát hơn cho việc học biến phân.</p><p>Ý tưởng chính đằng sau việc học biến phân là chúng ta có thể cực đại hoá <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> trên một họ phân phối hạn chế <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>. Họ phân phối này được chọn để có thể dễ dàng tính toán <span class="mathjax"><span class="MathJax_Preview">\mathbb{E}_{q} \log p(\boldsymbol{h, v})</span><script type="math/tex">\mathbb{E}_{q} \log p(\boldsymbol{h, v})</script></span>. Một cách thường dùng là đưa ra các giả định về việc phân tích <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> thành các nhân tố như thế nào.</p><p>Một cách tiếp cận phổ biến để học biến phân là áp đặt một hạn chế rằng <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> là một phân phối giai thừa:</p><p><span class="mathjax"><span class="MathJax_Preview"> q(\boldsymbol{h\space|\space v}) = \prod_{i} q(h_i \space | \space \boldsymbol{v}). \tag{19.17}</span><script type="math/tex; mode=display"> q(\boldsymbol{h\space|\space v}) = \prod_{i} q(h_i \space | \space \boldsymbol{v}). \tag{19.17}</script></span></p><p>Cách tiếp cận này được gọi là phương pháp <strong>trường trung bình (mean field)</strong>. Một cách tổng quát hơn, chúng ta có thể áp đặt bất cứ cấu trúc mô hình đồ thị nào mà ta chọn vào <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>, để xác định một cách linh động bao nhiêu tương tác mà ta muốn phép xấp xỉ nắm bắt. Mô hình đồ thị tổng quát này được gọi là <strong>suy luận biến phân hướng cấu trúc (structured variational inference)</strong> (Saul và Jordan, 1996).</p><p>Vẻ đẹp của phương pháp này là chúng ta không cần phải xác định một dạng tham số cụ thể cho <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>. Chúng ta định rõ cách nó phân tích thành các nhân tố, nhưng sau đó bài toán tối ưu hoá sẽ xác định phân phối xác suất tối ưu trong phạm vi những ràng buộc của sự phân tích trên. Đối với các biến ẩn rời rạc, điều đó có nghĩa là chúng ta sử dụng các kỹ thuật tối ưu hóa truyền thống để tối ưu hóa lượng hữu hạn các biến số mô tả phân phối <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>. Đối với những biến ẩn liên tục, điều đó có nghĩa là chúng ta vận dụng một nhánh của toán học được gọi là giải tích biến phân để tối ưu trên một miền không gian của các hàm số và xác định hàm nào sẽ được dùng để biểu diễn <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>. Giải tích biến phân là khởi nguồn của những cái tên “học biến phân” và “suy luận biến phân”, mặc dù những cái tên này thậm chí được dùng trong trường hợp những biến ẩn là rời rạc và giải tích biến phân là không cần thiết. Với những biến ẩn liên tục, giải tích biến phân là một kỹ thuật cực mạnh để xoá bỏ gánh nặng cho người thiết kế mô hình, khi mà bây giờ người thiết kế mô hình chỉ cần xác định cách <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> phân tích thành các nhân tố, hơn là phải đoán xem làm cách nào để thiết kế <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> để có thể xấp xỉ hậu nghiệm một cách chính xác.</p><p>Bởi vì <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}(\boldsymbol{v}, \boldsymbol{\theta}, q)</span><script type="math/tex">\mathcal{L}(\boldsymbol{v}, \boldsymbol{\theta}, q)</script></span> được định nghĩa là <span class="mathjax"><span class="MathJax_Preview">\log p(\boldsymbol{v}; \boldsymbol{\theta}) - D_{KL}(q(\boldsymbol{h\space|\space v}) \parallel p(\boldsymbol{h} | \boldsymbol{v}; \boldsymbol{\theta}))</span><script type="math/tex">\log p(\boldsymbol{v}; \boldsymbol{\theta}) - D_{KL}(q(\boldsymbol{h\space|\space v}) \parallel p(\boldsymbol{h} | \boldsymbol{v}; \boldsymbol{\theta}))</script></span>, chúng ta có thể hiểu rằng việc cực đại hóa <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> theo <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> giống như cực tiểu hóa <span class="mathjax"><span class="MathJax_Preview">D_{KL}((q(\boldsymbol{h\space|\space v}) \parallel p(\boldsymbol{h} \space|\space \boldsymbol{v}))</span><script type="math/tex">D_{KL}((q(\boldsymbol{h\space|\space v}) \parallel p(\boldsymbol{h} \space|\space \boldsymbol{v}))</script></span>.</p><p>Nghĩa là, chúng ta điều chỉnh <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> cho khớp với <span class="mathjax"><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>. Tuy nhiên, ta đang làm điều này theo hướng phân kỳ KL trái ngược với cách ta thường dùng để điểu chỉnh một xấp xỉ. Khi chúng ta dùng học hợp lý cực đại để điều chỉnh một mô hình khớp với dữ liệu, ta cực tiểu hóa <span class="mathjax"><span class="MathJax_Preview">D_{KL}(p_{data} \parallel p_{model})</span><script type="math/tex">D_{KL}(p_{data} \parallel p_{model})</script></span>. Như đã mô tả trong hình 3.6, hợp lý cực đại khyến khích mô hình cho xác suất cao ở mọi điểm mà dữ liệu có xác suất cao, trong khi đó thủ tục suy luận dựa vào tối ưu hóa khuyến khích <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> lấy xác suất thấp tại mọi điểm mà hậu nghiệm thực có xác suất thấp. Cả hai hướng của phân kỳ KL đều có những tính chất mong muốn và không mong muốn. Lựa chọn phương pháp nào để sử dụng tuỳ thuộc vào việc thuộc tính nào được ưu tiên nhất trong mỗi ứng dụng. Trong các bài toán suy luận tối ưu, chúng ta dùng <span class="mathjax"><span class="MathJax_Preview">D_{KL}(q(\boldsymbol{h} | \boldsymbol{v}) \parallel p(\boldsymbol{h} | \boldsymbol{v}))</span><script type="math/tex">D_{KL}(q(\boldsymbol{h} | \boldsymbol{v}) \parallel p(\boldsymbol{h} | \boldsymbol{v}))</script></span> vì lý do tính toán. Cụ thể, để tính toán <span class="mathjax"><span class="MathJax_Preview">D_{KL}(q(\boldsymbol{h} | \boldsymbol{v}) \parallel p(\boldsymbol{h} | \boldsymbol{v}))</span><script type="math/tex">D_{KL}(q(\boldsymbol{h} | \boldsymbol{v}) \parallel p(\boldsymbol{h} | \boldsymbol{v}))</script></span>, chúng ta phải tính toán các kỳ vọng theo <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>, và bằng cách thiết kế <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> đơn giản, chúng ta có thể đơn giản hoá các kỳ vọng cần tính. Hướng ngược lại của phân kỳ KL sẽ yêu cầu chúng ta tính giá trị kỳ vọng theo hậu nghiệm thực. Bởi vì dạng hậu nghiệm thực được quyết định bởi sự lựa chọn mô hình, chúng ta không thể nào thiết kế một cách tiếp cận ít tốn kém hơn để tính chính xác <span class="mathjax"><span class="MathJax_Preview">D_{KL}(p(\boldsymbol{h} | \boldsymbol{v}) \parallel q(\boldsymbol{h} | \boldsymbol{v}))</span><script type="math/tex">D_{KL}(p(\boldsymbol{h} | \boldsymbol{v}) \parallel q(\boldsymbol{h} | \boldsymbol{v}))</script></span>.</p><h2 id="1941-Các-biến-ẩn-rời-rạc"><a class="anchor hidden-xs" href="#1941-Các-biến-ẩn-rời-rạc" title="1941-Các-biến-ẩn-rời-rạc"><span class="octicon octicon-link"></span></a>19.4.1 Các biến ẩn rời rạc</h2><p>Suy luận biến phân với các biến ẩn rời rạc tương đối đơn giản. Chúng ta định nghĩa một phân phối <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>, mà mỗi nhân tố của <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> được định nghĩa chỉ bằng một bảng tra cứu trên những trạng thái rời rạc. Trong trường hợp đơn giản nhất, <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> là nhị phân và chúng ta có thể tạo ra một giả định trường trung bình rằng <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> phân tích thành từng <span class="mathjax"><span class="MathJax_Preview">h_i</span><script type="math/tex">h_i</script></span> riêng biệt. Trong trường hợp này, chúng ta có thể tham số hóa <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> bằng một vector <span class="mathjax"><span class="MathJax_Preview">\hat{\boldsymbol{h}}</span><script type="math/tex">\hat{\boldsymbol{h}}</script></span> mà phần tử của nó là các xác suất. Khi đó <span class="mathjax"><span class="MathJax_Preview">q(h_i=1 \space|\space \boldsymbol{v}) = \hat{h_i}</span><script type="math/tex">q(h_i=1 \space|\space \boldsymbol{v}) = \hat{h_i}</script></span></p><p>Sau khi xác định cách biểu diễn <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>, chúng ta đơn giản chỉ cần tối ưu các tham số của nó. Với các biến ẩn rời rạc, đây chỉ là bài toán tối ưu thông thường. Về nguyên tắc, ta có thể lựa chọn <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> bằng bất kỳ thuật toán tối ưu nào, chẳng hạn như trượt gradient.</p><p>Bởi vì việc tối ưu này phải xảy ra trong vòng lặp bên trong của một thuật toán học, nó phải rất nhanh. Để đạt đuợc tốc độ này, chúng ta thường dùng những thuật toán tối ưu đặc biệt được thiết kế để giải quyết những bài toán tương đối nhỏ và đơn giản trong một vài bước lặp. Một lựa chọn phổ biến là lặp qua những phương trình điểm cố định, hay nói cách khác, chúng ta giải phương trình<br>
<span class="mathjax"><span class="MathJax_Preview"> \frac{\partial}{\partial {\hat{h_i}}}\mathcal{L} = 0 \tag{19.18}</span><script type="math/tex; mode=display"> \frac{\partial}{\partial {\hat{h_i}}}\mathcal{L} = 0 \tag{19.18}</script></span></p><p>cho <span class="mathjax"><span class="MathJax_Preview">\hat{h_i}</span><script type="math/tex">\hat{h_i}</script></span>. Chúng ta liên tục cập nhật những phần tử khác nhau của <span class="mathjax"><span class="MathJax_Preview">\hat{\boldsymbol{h}}</span><script type="math/tex">\hat{\boldsymbol{h}}</script></span> cho đến khi thoả mãn điều kiện hội tụ.</p><p>Một cách cụ thể hơn, chúng ta trình bày cách áp dụng suy luận biến phân vào <strong>mô hình mã hoá thưa nhị phân (binary sparse coding model)</strong> (chúng tôi trình bày mô hình được phát triển bởi Henniges cùng cộng sự [2010] ở đây, nhưng diễn dịch bằng cách áp dụng  phương pháp trường trung bình cổ điển và tổng quát cho mô hình này, trong khi họ đưa ra một thuật toán chuyên biệt). Cách diễn dịch này đi vào chi tiết toán học và dành cho các độc giả muốn giải quyết hoàn toàn bất kỳ sự mơ hồ nào vè các diễn đạt có tính trừu tượng cao của phép suy luận và học biến phân mà chúng tôi đã trình bày. Những độc giả nào không có kế hoạch diễn dịch hoặc hiện thực các giải thuật học biến phân có thể bỏ qua phần này mà không sợ bỏ lỡ bất kì khái niệm bậc cao mới nào. Những độc giả đang tiếp tục với ví dụ mã hoá thưa nhị phân được khuyến khích xem lại danh sách các thuộc tính hữu ích của các hàm số thường được phát sinh trong những mô hình xác xuất ở phần 3.10. Chúng tôi dùng những thuộc tính này xuyên suốt các diễn dịch dưới đây mà không nhấn mạnh cụ thể khi nào tính chất nào sẽ sử dụng.</p><p>Trong mô hình mã hoá thưa nhị phân, giá trị đầu vào <span class="mathjax"><span class="MathJax_Preview">v \in \mathbb{R}^{n}</span><script type="math/tex">v \in \mathbb{R}^{n}</script></span> được sinh ra từ một mô hình bằng cách thêm nhiễu Gauss vào tổng của <span class="mathjax"><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span> thành phần khác nhau, mà mỗi thành phần có thể xuất hiện hoặc không. Mỗi thành phần được bật hay tắt bởi các đơn vị ẩn tương ứng trong <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h} \in \{0, 1\}^m</span><script type="math/tex">\boldsymbol{h} \in \{0, 1\}^m</script></span>:<br>
<span class="mathjax"><span class="MathJax_Preview">p(h_i = 1) = \sigma(b_i), \tag{19.19}</span><script type="math/tex; mode=display">p(h_i = 1) = \sigma(b_i), \tag{19.19}</script></span><br>
<span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{v \space|\space h}) = \mathcal{N}(\boldsymbol{v}; \boldsymbol{Wh}, \beta^{-1}), \tag{19.20} </span><script type="math/tex; mode=display">p(\boldsymbol{v \space|\space h}) = \mathcal{N}(\boldsymbol{v}; \boldsymbol{Wh}, \beta^{-1}), \tag{19.20} </script></span></p><p>trong đó <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{b}</span><script type="math/tex">\boldsymbol{b}</script></span> là tập hệ số tự do có thể học được, <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{W}</span><script type="math/tex">\boldsymbol{W}</script></span> là ma trận trọng số có thể học được, và <span class="mathjax"><span class="MathJax_Preview">\beta</span><script type="math/tex">\beta</script></span> là ma trận chéo chính xác có thể học được.</p><p>Để huấn luyện mô hình này với hợp lý hàm cực đại, ta cần phải lấy đạo hàm theo các tham số. Xét biểu thức đạo hàm theo một trong các hệ số tự do:</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}\\
&amp; &amp; \frac{\partial}{\partial b_i} \log p(\boldsymbol{v}) \tag{19.21}\\
&amp;=&amp; \frac{\frac{\partial}{\partial b_i} p(\boldsymbol{v})}{p(\boldsymbol{v})} \tag{19.22}\\
&amp;=&amp; \frac{\frac{\partial}{\partial b_i} \sum_{\boldsymbol{h}} p(\boldsymbol{h,v})}{p(\boldsymbol{v})} \tag{19.23}\\
&amp;=&amp;\frac{\frac{\partial}{\partial b_i} \sum_{\boldsymbol{h}} p(\boldsymbol{h})p(\boldsymbol{v\mid h})} {p(\boldsymbol{v})} \tag{19.24}\\
&amp;=&amp; \frac{\sum_{\boldsymbol{h}} p(\boldsymbol{v \space|\space h}) \frac{\partial}{\partial b_i}p(\boldsymbol{h})} {p(\boldsymbol{v})}\tag{19.25}\\
&amp;=&amp; \sum _{h} p ( \boldsymbol { h } \mid \boldsymbol { v } ) \frac { \frac { \partial } { \partial b _ { i } } p ( \boldsymbol { h } ) } { p ( \boldsymbol { h } ) } \tag{19.26}\\
&amp;=&amp; \mathbb { E } _ { \mathbf { h } \sim p ( \boldsymbol { h } | \boldsymbol { v } ) } \frac { \partial } { \partial b _ {i}} \log p(\boldsymbol{h}) \tag{19.27}\\
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}\\
& & \frac{\partial}{\partial b_i} \log p(\boldsymbol{v}) \tag{19.21}\\
&=& \frac{\frac{\partial}{\partial b_i} p(\boldsymbol{v})}{p(\boldsymbol{v})} \tag{19.22}\\
&=& \frac{\frac{\partial}{\partial b_i} \sum_{\boldsymbol{h}} p(\boldsymbol{h,v})}{p(\boldsymbol{v})} \tag{19.23}\\
&=&\frac{\frac{\partial}{\partial b_i} \sum_{\boldsymbol{h}} p(\boldsymbol{h})p(\boldsymbol{v\mid h})} {p(\boldsymbol{v})} \tag{19.24}\\
&=& \frac{\sum_{\boldsymbol{h}} p(\boldsymbol{v \space|\space h}) \frac{\partial}{\partial b_i}p(\boldsymbol{h})} {p(\boldsymbol{v})}\tag{19.25}\\
&=& \sum _{h} p ( \boldsymbol { h } \mid \boldsymbol { v } ) \frac { \frac { \partial } { \partial b _ { i } } p ( \boldsymbol { h } ) } { p ( \boldsymbol { h } ) } \tag{19.26}\\
&=& \mathbb { E } _ { \mathbf { h } \sim p ( \boldsymbol { h } | \boldsymbol { v } ) } \frac { \partial } { \partial b _ {i}} \log p(\boldsymbol{h}) \tag{19.27}\\
\\\end{eqnarray}</script></span></p><p>// Nguyễn Hoàng Dũng bắt đầu dịch ở đây — p639</p><p><img src="https://i.imgur.com/E22UWle.png" alt=""></p><blockquote>
<p>Hình 19.2: Cấu trúc đồ thị của một mô hình mã hóa thưa nhị phân với bốn đơn vị ẩn. (Hình bên trái) Cấu trúc đồ thị của <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{v},\boldsymbol{h})</span><script type="math/tex">p(\boldsymbol{v},\boldsymbol{h})</script></span>. Lưu ý rằng các cạnh của đồ thị đều có hướng, và với mỗi 2 đơn vị ẩn đều cùng là nốt cha của mọi đơn vị khả kiến. (Hình bên phải) Cấu trúc đồ thị của <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h}\mid \boldsymbol{v})</span><script type="math/tex">p(\boldsymbol{h}\mid \boldsymbol{v})</script></span>. Để giải thích cho những đường đi có hiệu lực giữa các nốt cùng là nốt cha, phân phối hậu nghiệm cần một cạnh nối giữa tất cả các đơn vị ẩn.</p>
</blockquote><p>Điều này đòi hỏi phải tính toán một kỳ vọng theo <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h}\mid \boldsymbol{v})</span><script type="math/tex">p(\boldsymbol{h}\mid \boldsymbol{v})</script></span>. Không may mắn thay, <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h}\mid \boldsymbol{v})</span><script type="math/tex">p(\boldsymbol{h}\mid \boldsymbol{v})</script></span> lại là một phân phối phức tạp. Tham khảo hình 19.2 cho cấu trúc đồ thị của <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{v},\boldsymbol{h})</span><script type="math/tex">p(\boldsymbol{v},\boldsymbol{h})</script></span> và <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h}\mid \boldsymbol{v})</span><script type="math/tex">p(\boldsymbol{h}\mid \boldsymbol{v})</script></span>. Phân phối hậu nghiệm tương ứng với một đồ thị đầy đủ trên các đơn vị ẩn, nên những thuật toán khử biến không giúp chúng ta tính toán các kỳ vọng cần thiết nhanh hơn giải thuật vét cạn.</p><p>Ta có thể giải quyết sự khó khăn này bằng cách sử dụng suy luận biến phân và học biến phân.<br>
Ta có thể tạo một xấp xỉ một trường trung bình như sau:</p><p><span class="mathjax"><span class="MathJax_Preview">q(\boldsymbol{h}\mid \boldsymbol{v}) = \prod_{i}q\left(h_{i}\mid \boldsymbol{v}\right) \tag{19.28}</span><script type="math/tex; mode=display">q(\boldsymbol{h}\mid \boldsymbol{v}) = \prod_{i}q\left(h_{i}\mid \boldsymbol{v}\right) \tag{19.28}</script></span></p><p>Các biến ẩn của mô hình mã hóa thưa nhị phân đều là nhị phân, nên để biểu diễn <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> giai thừa, chúng ta chỉ đơn giản mô hình hóa <span class="mathjax"><span class="MathJax_Preview">m</span><script type="math/tex">m</script></span> phân phối Bernoulli <span class="mathjax"><span class="MathJax_Preview">q({h}_{i} \space|\space \boldsymbol{v})</span><script type="math/tex">q({h}_{i} \space|\space \boldsymbol{v})</script></span>. Một cách tự nhiên để biểu diễn trung bình của các phân phối Bernoulli là dùng một vector các xác suất <span class="mathjax"><span class="MathJax_Preview">\hat{\boldsymbol{h}}</span><script type="math/tex">\hat{\boldsymbol{h}}</script></span>, với <span class="mathjax"><span class="MathJax_Preview">q\left(h_{i}=1 \space|\space\boldsymbol{v}\right) = \hat{h}_{i}</span><script type="math/tex">q\left(h_{i}=1 \space|\space\boldsymbol{v}\right) = \hat{h}_{i}</script></span>. Chúng ta áp đặt một ràng buộc rằng <span class="mathjax"><span class="MathJax_Preview">\hat{h}_{i}</span><script type="math/tex">\hat{h}_{i}</script></span> không thể bằng 0 hay 1, để tránh các lỗi trong quá trình tính toán, ví dụ như trường hợp tính <span class="mathjax"><span class="MathJax_Preview">\log\hat{h}_{i}</span><script type="math/tex">\log\hat{h}_{i}</script></span>.</p><p>Bằng các phép giải tích, chúng ta sẽ thấy rằng các phương trình suy luận biến phân không bao giờ gán giá trị 0 và 1 cho <span class="mathjax"><span class="MathJax_Preview">\hat{h}_{i}</span><script type="math/tex">\hat{h}_{i}</script></span>. Tuy nhiên, khi hiện thực chương trình, những sai số làm tròn của máy tính thường cho kết quả là các giá trị 0 hoặc 1. Trong lĩnh vực phần mềm, chúng ta mong muốn hiện thực mã hóa thưa nhị phân bằng cách sử dụng một vector tự do của các tham số biến phân <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{z}</span><script type="math/tex">\boldsymbol{z}</script></span> và thu được <span class="mathjax"><span class="MathJax_Preview">\hat{\boldsymbol{h}}</span><script type="math/tex">\hat{\boldsymbol{h}}</script></span> thông qua biểu thức <span class="mathjax"><span class="MathJax_Preview">\hat{\boldsymbol{h}} = \sigma(z)</span><script type="math/tex">\hat{\boldsymbol{h}} = \sigma(z)</script></span>. Từ đó, ta hoàn toàn có thể tính log <span class="mathjax"><span class="MathJax_Preview">\hat{h}_{i}</span><script type="math/tex">\hat{h}_{i}</script></span> trên máy tính bất kỳ bằng cách sử dụng đồng nhất log <span class="mathjax"><span class="MathJax_Preview">\sigma \left(z_{i} \right) = - \zeta \left(-z_{i} \right)</span><script type="math/tex">\sigma \left(z_{i} \right) = - \zeta \left(-z_{i} \right)</script></span>, thể hiện mối liên quan giữa hàm sigmoid và hàm softplus.</p><p>Để bắt đầu phép diễn dịch học biến phân trong mô hình mã hóa thưa nhị phân, ta chỉ ra rằng phép biến đổi xấp xỉ trường trung bình giúp việc học dễ tính toán.</p><p>Cận dưới thực nghiệm được xác định bởi</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}\\
        &amp; &amp;\mathcal { L } ( \boldsymbol { v } , \boldsymbol { \theta } , q )  \tag{19.29}  \\
&amp;=&amp; \mathbb { E } _ { \mathbf { h } \sim q } [ \log p ( \boldsymbol { h } , \boldsymbol { v } ) ] + H ( q )  \tag{19.30}  \\
        &amp;=&amp;  \mathbb { E } _ { \mathbf { h } \sim q } [ \log p ( \boldsymbol { h } ) + \log p ( \boldsymbol { v } \mid \boldsymbol { h } ) - \log q ( \boldsymbol { h } \mid \boldsymbol { v } ) ] \tag{19.31}  \\
        &amp;=&amp; \mathbb { E } _ { \mathbf { h } \sim q } \left[ \sum _ { i = 1 } ^ { m } \log p \left( h _ { i } \right) + \sum _ { i = 1 } ^ { n } \log p \left( v _ { i } | \boldsymbol { h } \right) - \sum _ { i = 1 } ^ { m } \log q \left( h _ { i } | \boldsymbol { v } \right) \right] \tag{19.32} \\
        &amp;=&amp; \sum _ { i = 1 } ^ { m } \left[ \hat { h } _ { i } \left( \log \sigma \left( b _ { i } \right) - \log \hat { h } _ { i } \right) + \left( 1 - \hat { h } _ { i } \right) \left( \log \sigma \left( - b _ { i } \right) - \log \left( 1 - \hat { h } _ { i } \right) \right) \right] \tag{19.33}\\
        &amp; &amp; + \mathbb { E } _ { \mathbf { h } \sim q } \left[ \sum _ { i = 1 } ^ { n } \log \sqrt { \frac { \beta _ { i } } { 2 \pi } } \exp \left( - \frac { \beta _ { i } } { 2 } \left( v _ { i } - \boldsymbol { W } _ { i , } \boldsymbol { h } \right) ^ { 2 } \right) \right] \tag{19.34}\\
        &amp;=&amp; \sum _ { i = 1 } ^ { m } \left[ \hat { h } _ { i } \left( \log \sigma \left( b _ { i } \right) - \log \hat { h } _ { i } \right) + \left( 1 - \hat { h } _ { i } \right) \left( \log \sigma \left( - b _ { i } \right) - \log \left( 1 - \hat { h } _ { i } \right) \right) \right] \tag{19.35}\\
        &amp; &amp; + \frac { 1 } { 2 } \sum _ { i = 1 } ^ { n } \left[ \log \frac { \beta _ { i } } { 2 \pi } - \beta _ { i } \left( v _ { i } ^ { 2 } - 2 v _ { i } \boldsymbol { W } _ { i , } \hat { \boldsymbol { h } } + \sum _ { j } \left[ W _ { i , j } ^ { 2 } \hat { h } _ { j } + \sum _ { k \neq j } W _ { i , j } W _ { i , k } \hat { h } _ { j } \hat { h } _ { k } \right] \right) \right] \tag{19.36}\\
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}\\
        & &\mathcal { L } ( \boldsymbol { v } , \boldsymbol { \theta } , q )  \tag{19.29}  \\
&=& \mathbb { E } _ { \mathbf { h } \sim q } [ \log p ( \boldsymbol { h } , \boldsymbol { v } ) ] + H ( q )  \tag{19.30}  \\
        &=&  \mathbb { E } _ { \mathbf { h } \sim q } [ \log p ( \boldsymbol { h } ) + \log p ( \boldsymbol { v } \mid \boldsymbol { h } ) - \log q ( \boldsymbol { h } \mid \boldsymbol { v } ) ] \tag{19.31}  \\
        &=& \mathbb { E } _ { \mathbf { h } \sim q } \left[ \sum _ { i = 1 } ^ { m } \log p \left( h _ { i } \right) + \sum _ { i = 1 } ^ { n } \log p \left( v _ { i } | \boldsymbol { h } \right) - \sum _ { i = 1 } ^ { m } \log q \left( h _ { i } | \boldsymbol { v } \right) \right] \tag{19.32} \\
        &=& \sum _ { i = 1 } ^ { m } \left[ \hat { h } _ { i } \left( \log \sigma \left( b _ { i } \right) - \log \hat { h } _ { i } \right) + \left( 1 - \hat { h } _ { i } \right) \left( \log \sigma \left( - b _ { i } \right) - \log \left( 1 - \hat { h } _ { i } \right) \right) \right] \tag{19.33}\\
        & & + \mathbb { E } _ { \mathbf { h } \sim q } \left[ \sum _ { i = 1 } ^ { n } \log \sqrt { \frac { \beta _ { i } } { 2 \pi } } \exp \left( - \frac { \beta _ { i } } { 2 } \left( v _ { i } - \boldsymbol { W } _ { i , } \boldsymbol { h } \right) ^ { 2 } \right) \right] \tag{19.34}\\
        &=& \sum _ { i = 1 } ^ { m } \left[ \hat { h } _ { i } \left( \log \sigma \left( b _ { i } \right) - \log \hat { h } _ { i } \right) + \left( 1 - \hat { h } _ { i } \right) \left( \log \sigma \left( - b _ { i } \right) - \log \left( 1 - \hat { h } _ { i } \right) \right) \right] \tag{19.35}\\
        & & + \frac { 1 } { 2 } \sum _ { i = 1 } ^ { n } \left[ \log \frac { \beta _ { i } } { 2 \pi } - \beta _ { i } \left( v _ { i } ^ { 2 } - 2 v _ { i } \boldsymbol { W } _ { i , } \hat { \boldsymbol { h } } + \sum _ { j } \left[ W _ { i , j } ^ { 2 } \hat { h } _ { j } + \sum _ { k \neq j } W _ { i , j } W _ { i , k } \hat { h } _ { j } \hat { h } _ { k } \right] \right) \right] \tag{19.36}\\
\\\end{eqnarray}</script></span></p><p>Những phương trình trên tuy có vẻ xấu xí, nhưng chúng cho thấy rằng <span class="mathjax"><span class="MathJax_Preview">\mathcal { L }</span><script type="math/tex">\mathcal { L }</script></span> có thể được biểu diễn bằng một số lượng nhỏ các phép toán số học đơn giản. Như vậy cận dưới thực nghiệm <span class="mathjax"><span class="MathJax_Preview">\mathcal { L }</span><script type="math/tex">\mathcal { L }</script></span> là dễ tính toán. Chúng ta có thể sử dụng <span class="mathjax"><span class="MathJax_Preview">\mathcal { L }</span><script type="math/tex">\mathcal { L }</script></span> để thay thế cho logarit hàm hợp lý khó tính toán.</p><p>Về cơ bản, ta có thể sử dụng phương pháp leo gradient cho cả <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span> và <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span>, dẫn đến một thuật toán kết hợp hoàn hảo phép suy luận và huấn luyện. Tuy nhiên, chúng ta thường không sử dụng phương pháp này vì hai lý do. Thứ nhất, việc này đòi hỏi lưu trữ <span class="mathjax"><span class="MathJax_Preview">\hat{\boldsymbol{h}}</span><script type="math/tex">\hat{\boldsymbol{h}}</script></span> với mỗi <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span>. Chúng ta thường ưu tiên các thuật toán không đòi hỏi bộ nhớ cho từng mẫu huấn luyện. Sẽ rất khó để nhân rộng giải thuật học cho hàng tỷ mẫu nếu ta phải ghi nhớ vector cập nhật động ứng với mỗi mẫu. Thứ hai, chúng ta mong muốn trích xuất các đặc trưng <span class="mathjax"><span class="MathJax_Preview">\hat { \boldsymbol { h } }</span><script type="math/tex">\hat { \boldsymbol { h } }</script></span> nhanh nhất có thể, để nhận diện được thông tin của <span class="mathjax"><span class="MathJax_Preview">\boldsymbol { v }</span><script type="math/tex">\boldsymbol { v }</script></span>. Trong một triển khai cài đặt thực tế, ta cũng mong muốn tính toán được <span class="mathjax"><span class="MathJax_Preview">\hat { \boldsymbol { h } }</span><script type="math/tex">\hat { \boldsymbol { h } }</script></span> trong thời gian thực.</p><p>Từ hai lý do nêu trên, chúng ta thường không sử dụng phương pháp trượt gradient để tính toán các tham số trường trung bình <span class="mathjax"><span class="MathJax_Preview">\hat { \boldsymbol { h } }</span><script type="math/tex">\hat { \boldsymbol { h } }</script></span>. Thay vào đó, ta ước lượng chúng một cách nhanh chóng bằng các phương trình điểm cố định.</p><p>Ý tưởng đằng sau của các phương trình điểm cố định là ta cần tìm kiếm một cực đại cục bộ theo <span class="mathjax"><span class="MathJax_Preview">\hat { \boldsymbol { h } }</span><script type="math/tex">\hat { \boldsymbol { h } }</script></span>, khi <span class="mathjax"><span class="MathJax_Preview">\nabla _ { \boldsymbol { h } } \mathcal { L } ( \boldsymbol { v } , \boldsymbol { \theta } , \hat { \boldsymbol { h } } ) = \mathbf { 0 }</span><script type="math/tex">\nabla _ { \boldsymbol { h } } \mathcal { L } ( \boldsymbol { v } , \boldsymbol { \theta } , \hat { \boldsymbol { h } } ) = \mathbf { 0 }</script></span>. Sẽ không hiệu quả nếu chúng ta giải phương trình này cùng lúc đối với mọi <span class="mathjax"><span class="MathJax_Preview">\hat { \boldsymbol { h } }</span><script type="math/tex">\hat { \boldsymbol { h } }</script></span>. Tuy nhiên, ta có thể giải theo một biến riêng lẻ:</p><p><span class="mathjax"><span class="MathJax_Preview">\frac { \partial } { \partial \hat { h } _ { i } } \mathcal { L } ( v , \theta , \hat { h } ) = 0 \tag{19.37}</span><script type="math/tex; mode=display">\frac { \partial } { \partial \hat { h } _ { i } } \mathcal { L } ( v , \theta , \hat { h } ) = 0 \tag{19.37}</script></span></p><p>Chúng ta có thể lặp đi lặp lại việc áp dụng lời giải của phương trình trên với <span class="mathjax"><span class="MathJax_Preview">i = 1 , \dots , m,</span><script type="math/tex">i = 1 , \dots , m,</script></span> và tiếp tục chu kỳ này cho đến khi thỏa mãn điều kiện hội tụ. Các điều kiện hội tụ phổ biến bao gồm việc dừng vòng lặp khi một chu kỳ cập nhật đầy đủ không cải thiện <span class="mathjax"><span class="MathJax_Preview">\mathcal { L }</span><script type="math/tex">\mathcal { L }</script></span> vượt qua một dung sai nào đó, hay khi chu kỳ không thể thay đổi <span class="mathjax"><span class="MathJax_Preview">\hat { \boldsymbol { h } }</span><script type="math/tex">\hat { \boldsymbol { h } }</script></span> với độ lệch vượt qua một giá trị nào đó.</p><p>Phép lặp qua các phương trình điểm cố định của trường trung bình là một kĩ thuật có thể cung cấp phép suy luận biến phân nhanh trên nhiều loại mô hình. Để cho rõ ràng hơn, chúng tôi sẽ trình bày cách suy ra các cập nhật cho mô hình mã hóa thưa nhị phân nói riêng.</p><p>Đầu tiên, chúng ta phải biểu diễn được đạo hàm theo <span class="mathjax"><span class="MathJax_Preview">\hat { h } _ { i }</span><script type="math/tex">\hat { h } _ { i }</script></span>. Để làm được điều này, ta thế phương trình 19.36 vào vế trái của phương trình 19.37:</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}\\
&amp; &amp;\frac { \partial } { \partial \hat { h } _ { i } } \mathcal { L } ( \boldsymbol { v } , \boldsymbol { \theta } , \hat { \boldsymbol { h } } ) \tag{19.38} \\
&amp;=&amp;\frac { \partial } { \partial \hat { h } _ { i } } [ \sum _ { j = 1 } ^ { m } \left[ \hat { h } _ { j } \left( \log \sigma \left( b _ { j } \right) - \log \hat { h } _ { j } \right) + \left( 1 - \hat { h } _ { j } \right) \left( \log \sigma \left( - b _ { j } \right) - \log \left( 1 - \hat { h } _ { j } \right) \right) \right] \tag{19.39} \\
&amp; &amp;+ \frac { 1 } { 2 } \sum _ { j = 1 } ^ { n } \left[ \log \frac { \beta _ { j } } { 2 \pi } - \beta _ { j } \left( v _ { j } ^ { 2 } - 2 v _ { j } \boldsymbol { W } _ { j , } \hat { \boldsymbol { h } } + \sum _ { k } \left[ W _ { j , k } ^ { 2 } \hat { h } _ { k } + \sum _ { l \neq k } W _ { j , k } W _ { j , l } \hat { h } _ { k } \hat { h } _ { l } \right] \right) \right] \tag{19.40} \\
&amp;=&amp; \log \sigma \left( b _ { i } \right) - \log \hat { h } _ { i } - 1 + \log \left( 1 - \hat { h } _ { i } \right) + 1 - \log \sigma \left( - b _ { i } \right) \tag{19.41} \\
&amp; &amp;+ \sum _ { j = 1 } ^ { n } \left[ \beta _ { j } \left( v _ { j } W _ { j , i } - \frac { 1 } { 2 } W _ { j , i } ^ { 2 } - \sum _ { k \neq i } \boldsymbol { W } _ { j , k } \boldsymbol { W } _ { j , i } \hat { h } _ { k } \right) \right] \tag{19.42} \\
&amp;=&amp; b _ { i } - \log \hat { h } _ { i } + \log \left( 1 - \hat { h } _ { i } \right) + \boldsymbol { v } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } - \frac { 1 } { 2 } \boldsymbol { W } _ { : , i } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } - \sum _ { j \neq i } \boldsymbol { W } _ { : j } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } \hat { h } _ { j }\tag{19.43} \\
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}\\
& &\frac { \partial } { \partial \hat { h } _ { i } } \mathcal { L } ( \boldsymbol { v } , \boldsymbol { \theta } , \hat { \boldsymbol { h } } ) \tag{19.38} \\
&=&\frac { \partial } { \partial \hat { h } _ { i } } [ \sum _ { j = 1 } ^ { m } \left[ \hat { h } _ { j } \left( \log \sigma \left( b _ { j } \right) - \log \hat { h } _ { j } \right) + \left( 1 - \hat { h } _ { j } \right) \left( \log \sigma \left( - b _ { j } \right) - \log \left( 1 - \hat { h } _ { j } \right) \right) \right] \tag{19.39} \\
& &+ \frac { 1 } { 2 } \sum _ { j = 1 } ^ { n } \left[ \log \frac { \beta _ { j } } { 2 \pi } - \beta _ { j } \left( v _ { j } ^ { 2 } - 2 v _ { j } \boldsymbol { W } _ { j , } \hat { \boldsymbol { h } } + \sum _ { k } \left[ W _ { j , k } ^ { 2 } \hat { h } _ { k } + \sum _ { l \neq k } W _ { j , k } W _ { j , l } \hat { h } _ { k } \hat { h } _ { l } \right] \right) \right] \tag{19.40} \\
&=& \log \sigma \left( b _ { i } \right) - \log \hat { h } _ { i } - 1 + \log \left( 1 - \hat { h } _ { i } \right) + 1 - \log \sigma \left( - b _ { i } \right) \tag{19.41} \\
& &+ \sum _ { j = 1 } ^ { n } \left[ \beta _ { j } \left( v _ { j } W _ { j , i } - \frac { 1 } { 2 } W _ { j , i } ^ { 2 } - \sum _ { k \neq i } \boldsymbol { W } _ { j , k } \boldsymbol { W } _ { j , i } \hat { h } _ { k } \right) \right] \tag{19.42} \\
&=& b _ { i } - \log \hat { h } _ { i } + \log \left( 1 - \hat { h } _ { i } \right) + \boldsymbol { v } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } - \frac { 1 } { 2 } \boldsymbol { W } _ { : , i } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } - \sum _ { j \neq i } \boldsymbol { W } _ { : j } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } \hat { h } _ { j }\tag{19.43} \\
\\\end{eqnarray}</script></span></p><p>Để áp dụng quy luật suy luận cập nhật điểm cố định, chúng ta giải <span class="mathjax"><span class="MathJax_Preview">\hat { h } _ { i }</span><script type="math/tex">\hat { h } _ { i }</script></span> để phương trình 19.43 nhận giá trị là 0:</p><p><span class="mathjax"><span class="MathJax_Preview">\hat { h } _ { i } = \sigma \left( b _ { i } + \boldsymbol { v } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } - \frac { 1 } { 2 } \boldsymbol { W } _ { : , i } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { ; , i } - \sum _ { j \neq i } \boldsymbol { W } _ { : j } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } \hat { h } _ { j } \right) \tag{19.44}</span><script type="math/tex; mode=display">\hat { h } _ { i } = \sigma \left( b _ { i } + \boldsymbol { v } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } - \frac { 1 } { 2 } \boldsymbol { W } _ { : , i } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { ; , i } - \sum _ { j \neq i } \boldsymbol { W } _ { : j } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } \hat { h } _ { j } \right) \tag{19.44}</script></span></p><p>Đến đây, ta có thể thấy được sự liên kết chặt chẽ giữa mạng neuron truy hồi và phép suy luận trong mô hình đồ thị. Đặc biệt, các phương trình điểm cố định của trường trung bình định nghĩa một mạng neuron truy hồi. Nhiệm vụ của mạng này là thực hiện phép suy luận. Chúng tôi đã mô tả cách thu được mạng này từ một mô tả mô hình, tuy nhiên việc huấn luyện trực tiếp một mạng suy luận cũng có thể thực hiện được. Một vài ý tưởng dựa trên chủ đề này sẽ được đề cập trong chương 20.</p><p>Trong trường hợp mã hóa thưa nhị phân, ta thấy rằng liên kết của mạng truy hồi được xác định bởi phương trình 19.44 bao gồm việc liên tục cập nhật các đơn vị ẩn dựa trên sự thay đổi giá trị của các đơn vị ẩn láng giềng. Đầu vào luôn luôn gửi một thông điệp cố định <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}^{\top} \beta\boldsymbol{W}</span><script type="math/tex">\boldsymbol{v}^{\top} \beta\boldsymbol{W}</script></span> đến các đơn vị ẩn, nhưng các đơn vị ẩn lại liên tục cập nhật các thông điệp mà chúng gửi cho nhau. Cụ thể, hai đơn vị ẩn <span class="mathjax"><span class="MathJax_Preview">\hat{h}_{i}</span><script type="math/tex">\hat{h}_{i}</script></span> và <span class="mathjax"><span class="MathJax_Preview">\hat{h}_{j}</span><script type="math/tex">\hat{h}_{j}</script></span> kiềm chế lẫn nhau khi các vector trọng số của chúng thẳng hàng. Đây là một dạng cạnh tranh - giữa hai đơn vị ẩn có cùng vai trò diễn dịch đầu vào, chỉ có đơn vị nào giải thích tốt hơn mới được phép giữ hiệu lực. Sự cạnh tranh này đến từ những cố gắng của xấp xỉ trường trung bình nhằm nắm bắt các tương tác thanh minh trong hậu nghiệm mã hóa thưa nhị phân. Hiệu ứng thanh minh thực tế sẽ gây nên một hậu nghiệm đa mode, sao cho nếu ta lấy mẫu từ phân phối hậu nghiệm, một số mẫu sẽ có một đơn vị này có hiệu lực, một số mẫu khác sẽ có đơn vị khác có hiệu lực, và chỉ một số ít mẫu có cả hai đơn vị cùng có hiệu lực. Không may thay, các tương tác thanh minh không thể được mô hình hoá bởi <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> giai thừa dùng cho trường trung bình, vì vậy phương pháp xấp xỉ trường trung bình bắt buộc phải chọn một mode để mô hình hóa. Đây chính là ví dụ cho hành vi được mô tả ở hình 3.6.</p><p>Chúng ta có thể viết lại phương trình 19.44 dưới một dạng tương đương giúp gợi mở được nhiều góc nhìn sâu hơn:</p><p><span class="mathjax"><span class="MathJax_Preview">\hat { h } _ { i } = \sigma \left( b _ { i } + \left( v - \sum _ { j \neq i } \boldsymbol { W } : , \hat { h } _ { j } \right) ^ { \top } \beta \boldsymbol { W } _ { : , i } - \frac { 1 } { 2 } \boldsymbol { W } _ { : , i } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } \right)\tag{19.45}</span><script type="math/tex; mode=display">\hat { h } _ { i } = \sigma \left( b _ { i } + \left( v - \sum _ { j \neq i } \boldsymbol { W } : , \hat { h } _ { j } \right) ^ { \top } \beta \boldsymbol { W } _ { : , i } - \frac { 1 } { 2 } \boldsymbol { W } _ { : , i } ^ { \top } \boldsymbol { \beta } \boldsymbol { W } _ { : , i } \right)\tag{19.45}</script></span></p><p>Sau khi thay đổi công thức, ta thấy rằng đầu vào tại mỗi bước bao gồm <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v} - \sum _ { j \neq i } \boldsymbol { W } _ { : j } \hat { h } _ { j }</span><script type="math/tex">\boldsymbol{v} - \sum _ { j \neq i } \boldsymbol { W } _ { : j } \hat { h } _ { j }</script></span> hơn là <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span>. Do đó ta có thể hiểu rằng các đơn vị <span class="mathjax"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> cố gắng mã hóa những sai số thặng dư của <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span>, khi biết bộ mã của những đơn vị còn lại. Vì vậy mã hóa thưa giống như một bộ tự động mã hóa lặp, liên tục mã hóa và giải mã đầu vào của nó, cố gắng sửa những lỗi sai trong quá trình phục hồi dữ liệu sau mỗi vòng lặp.<br>
Trong ví dụ này, chúng ta đã thu được một quy luật cập nhật giúp cập nhật từng đơn vị tại một thời điểm. Nó sẽ tốt hơn nếu tại cùng thời điểm ta có thể cập nhật đồng thời nhiều đơn vị. Một số mô hình đồ thị, ví dụ như mô hình máy Boltzmann đa tầng, được kiến trúc để giúp ta giải đồng thời nhiều phần tử của <span class="mathjax"><span class="MathJax_Preview">\hat{\boldsymbol{h}}</span><script type="math/tex">\hat{\boldsymbol{h}}</script></span>. Không may thay, mã hóa thưa nhị phân lại không cho phép việc cập nhật theo từng khối. Thay vào đó, ta có thể sử dụng kỹ thuật heuristic được gọi là <strong>giảm xóc (damping)</strong> để thực hiện việc cập nhật các khối. Trong cách tiếp cận này, chúng ta tìm giá trị tối ưu cho mỗi <span class="mathjax"><span class="MathJax_Preview">\hat{\boldsymbol{h}}</span><script type="math/tex">\hat{\boldsymbol{h}}</script></span> riêng biệt, sau đó dịch chuyển các giá trị này với một bước nhỏ theo hướng tối ưu của chúng. Phương pháp này không được đảm bảo sẽ tăng <span class="mathjax"><span class="MathJax_Preview">\mathcal { L }</span><script type="math/tex">\mathcal { L }</script></span> theo mỗi bước, nhưng nó hoạt động tốt trong nhiều mô hình thực nghiệm. Tham khảo Koller and Friedman (2009) để biết thêm về cách lựa chọn cấp bậc đồng bộ hóa và kỹ thuật giảm xóc trong các giải thuật truyền thông điệp.</p><h2 id="1942-Phương-pháp-tính-các-biến-phân"><a class="anchor hidden-xs" href="#1942-Phương-pháp-tính-các-biến-phân" title="1942-Phương-pháp-tính-các-biến-phân"><span class="octicon octicon-link"></span></a>19.4.2 Phương pháp tính các biến phân</h2><p>Trước khi tiếp tục với phần trình bày về phương pháp học biến phân. chúng tôi giới thiệu ngắn gọn một tập hợp các công cụ toán học quan trọng trong phần này: <strong>Phương pháp tính biến phân (calculus of variations)</strong>.</p><p>Hầu hết các kĩ thuật học máy đều dựa trên việc tối thiểu một hàm <span class="mathjax"><span class="MathJax_Preview">J ( \boldsymbol { \theta } )</span><script type="math/tex">J ( \boldsymbol { \theta } )</script></span> bằng cách tìm kiếm vector đầu vào <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta} \in \mathbb { R } ^ { n }</span><script type="math/tex">\boldsymbol{\theta} \in \mathbb { R } ^ { n }</script></span> để nó có thể đạt giá trị nhỏ nhất. Điều này có thể được thực hiện bằng phương pháp tính đa lượng biến và đại số tuyến tính, bằng cách tìm một điểm giới hạn thỏa phương trình <span class="mathjax"><span class="MathJax_Preview">\nabla _ { \boldsymbol { \theta } } J ( \boldsymbol { \theta } ) = 0</span><script type="math/tex">\nabla _ { \boldsymbol { \theta } } J ( \boldsymbol { \theta } ) = 0</script></span>. Trong một số trường hợp, ta mong muốn tìm một hàm <span class="mathjax"><span class="MathJax_Preview">f ( \boldsymbol { x } )</span><script type="math/tex">f ( \boldsymbol { x } )</script></span>, chẳng hạn như khi ta muốn tìm hàm mật độ xác suất của một biến ngẫu nhiên nào đó. Chúng ta có thể thực hiện điều này nhờ phương pháp tính biến phân.</p><p>Một hàm của hàm <span class="mathjax"><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> được gọi là <strong>phiếm hàm (functional)</strong> <span class="mathjax"><span class="MathJax_Preview">J[f]</span><script type="math/tex">J[f]</script></span>. Giống như việc lấy đạo hàm bán phần của một hàm theo các phần tử thuộc vector đối số của hàm, ta cũng có thể lấy <strong>đạo hàm phiếm hàm (functional derivatives)</strong>, hay còn gọi là <strong>đạo hàm biến phân (variational derivatives)</strong>, của phiếm hàm <span class="mathjax"><span class="MathJax_Preview">J[f]</span><script type="math/tex">J[f]</script></span> theo từng giá trị đơn lẻ của hàm <span class="mathjax"><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span> tại bất kì giá trị của <span class="mathjax"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>. Đạo hàm phiếm hàm của phiếm hàm <span class="mathjax"><span class="MathJax_Preview">J</span><script type="math/tex">J</script></span> theo giá trị của hàm <span class="mathjax"><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> tại điểm <span class="mathjax"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> được kí hiệu là <span class="mathjax"><span class="MathJax_Preview">\frac { \delta } { \delta f ( x ) } J</span><script type="math/tex">\frac { \delta } { \delta f ( x ) } J</script></span>.<br>
Việc đề cập đến các ứng dụng hoàn chỉnh của đạo hàm phiếm hàm vượt ngoài khuôn khổ của cuốn sách này. Ở đây, chúng ta chỉ cần biết rằng, với những hàm <span class="mathjax"><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span> khả vi và <span class="mathjax"><span class="MathJax_Preview">g(y,x)</span><script type="math/tex">g(y,x)</script></span> khả vi có đạo hàm liên tục, thì<br>
<span class="mathjax"><span class="MathJax_Preview">\frac { \delta } { \delta f ( \boldsymbol { x } ) } \int g ( f ( \boldsymbol { x } ) , \boldsymbol { x } ) d \boldsymbol { x } = \frac { \partial } { \partial y } g ( f ( \boldsymbol { x } ) , \boldsymbol { x } )\tag{19.46}</span><script type="math/tex; mode=display">\frac { \delta } { \delta f ( \boldsymbol { x } ) } \int g ( f ( \boldsymbol { x } ) , \boldsymbol { x } ) d \boldsymbol { x } = \frac { \partial } { \partial y } g ( f ( \boldsymbol { x } ) , \boldsymbol { x } )\tag{19.46}</script></span></p><p>Nguyễn Hoàng Dũng kết thúc dịch ở đây — P643</p><p>-----------------------<br>
Hưng Nguyễn dịch từ đây (cuối trang 643, sau công thức 19.46)<br>
-----------------------</p><p>Để có cái nhìn trực giác về phép đồng nhất này, ta có thể hình dung <span class="mathjax"><span class="MathJax_Preview">f(\boldsymbol{x})</span><script type="math/tex">f(\boldsymbol{x})</script></span> là một vector với vô số phần tử, được đánh số bởi vector thực <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{x}</span><script type="math/tex">\boldsymbol{x}</script></span>. Theo góc nhìn (chưa trọn vẹn trong một mức độ nào đó) này, phép đồng nhất trên cũng giống với kết quả ta thu được cho một vector <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta} \in \mathbb{R}^n</span><script type="math/tex">\boldsymbol{\theta} \in \mathbb{R}^n</script></span> được đánh số bởi các số nguyên dương:</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
\frac{\partial}{\partial\theta_i}\sum_{j}g(\theta_j, j)=\frac{\partial}{\partial\theta_i}g(\theta_i, i) \tag{19.47}
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
\frac{\partial}{\partial\theta_i}\sum_{j}g(\theta_j, j)=\frac{\partial}{\partial\theta_i}g(\theta_i, i) \tag{19.47}
\\\end{eqnarray}</script></span></p><p>Nhiều kết quả trong các nghiên cứu học máy khác sử dụng <strong>phương trình Euler-Lagrange</strong> tổng quát hơn, cho phép <span class="mathjax"><span class="MathJax_Preview">g</span><script type="math/tex">g</script></span> phụ thuộc đồng thời vào các đạo hàm của <span class="mathjax"><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> cũng như bản thân <span class="mathjax"><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span>. Tuy nhiên chúng ta không cần dạng tổng quát đầy đủ này trong phạm vi cuốn sách này.</p><p>Để tối ưu một hàm số theo một vector, chúng ta lấy gradient của hàm số theo vector đó và tìm những điểm mà tại đó các phần tử của gradient bằng 0. Tương tự như vậy, ta có thể tối ưu một phiếm hàm bằng cách tìm những hàm số mà đạo hàm phiếm hàm tại mọi điểm của nó bằng 0.</p><p>Để minh họa cho phương pháp này, ta xem xét bài toán tìm hàm phân phối xác suất theo <span class="mathjax"><span class="MathJax_Preview">x \in \mathbb{R}</span><script type="math/tex">x \in \mathbb{R}</script></span> có entropy khả vi lớn nhất. Nhắc lại rằng entropy của một phân phối xác suất <span class="mathjax"><span class="MathJax_Preview">p(x)</span><script type="math/tex">p(x)</script></span> được định nghĩa như sau</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
H\left[p\right] = -\mathbb{E}_x\log p\left(x\right) \tag{19.48}
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
H\left[p\right] = -\mathbb{E}_x\log p\left(x\right) \tag{19.48}
\\\end{eqnarray}</script></span></p><p>Đối với các biến liên tục, giá trị kỳ vọng <span class="mathjax"><span class="MathJax_Preview">H[p]</span><script type="math/tex">H[p]</script></span> là một tích phân:</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
\displaystyle H\left[p\right] = -\int p\left(x\right)\log p\left(x\right)dx \tag{19.49}
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
\displaystyle H\left[p\right] = -\int p\left(x\right)\log p\left(x\right)dx \tag{19.49}
\\\end{eqnarray}</script></span></p><p>Ta không thể đơn giản cực đại hóa <span class="mathjax"><span class="MathJax_Preview">H[p]</span><script type="math/tex">H[p]</script></span> theo <span class="mathjax"><span class="MathJax_Preview">p(x)</span><script type="math/tex">p(x)</script></span>, bởi kết quả có thể không phải là một phân phối xác suất. Thay vào đó, chúng ta cần sử dụng các nhân tử Lagrange để ràng buộc <span class="mathjax"><span class="MathJax_Preview">p(x)</span><script type="math/tex">p(x)</script></span> có tích phân bằng 1. Kèm theo đó, entropy phải tăng không giới hạn khi phương sai tăng. Điều này khiến cho câu hỏi phân phối nào có entropy lớn nhất không còn đáng chú ý mà thay vào đó, chúng ta quan tâm đến phân phối có entropy lớn nhất khi phương sai <span class="mathjax"><span class="MathJax_Preview">\sigma^2</span><script type="math/tex">\sigma^2</script></span> không đổi. Sau cùng, bài toán là bất định bởi phân phối có thể dịch chuyển tùy ý mà không làm thay đổi entropy. Để đạt được nghiệm duy nhất, ta cần thêm một ràng buộc rằng giá trị trung bình của phân phối bằng <span class="mathjax"><span class="MathJax_Preview">\mu</span><script type="math/tex">\mu</script></span>. Phiếm hàm Lagrangian cho bài toán tối ưu này là:</p><blockquote>
<p>DN: từ “underditermined” dịch là “chưa xác định” có vẻ không được sát nghĩa lắm.<br>
TL: từ “underdetermined” tạm dịch thành “bất định”</p>
</blockquote><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
\mathcal {L}\left[p\right] &amp;=&amp; \lambda_1\left(\int p\left(x \right)dx-1\right)+\lambda_2\left(\mathbb{E}\left[x\right]-\mu\right)+\lambda_3\left(\mathbb{E}\left[\left(x-\mu\right)^2\right]-\sigma^2\right)+H\left[p\right] \tag{19.50}\\
&amp;=&amp;\int\left(\lambda_1p\left(x\right)+\lambda_2p\left(x\right)x+\lambda_3p\left(x\right)\left(x-\mu\right)^2+p\left(x\right)\log p\left(x\right)\right)dx-\lambda_1-\mu\lambda_2-\sigma^2\lambda_3 \tag{19.51}
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
\mathcal {L}\left[p\right] &=& \lambda_1\left(\int p\left(x \right)dx-1\right)+\lambda_2\left(\mathbb{E}\left[x\right]-\mu\right)+\lambda_3\left(\mathbb{E}\left[\left(x-\mu\right)^2\right]-\sigma^2\right)+H\left[p\right] \tag{19.50}\\
&=&\int\left(\lambda_1p\left(x\right)+\lambda_2p\left(x\right)x+\lambda_3p\left(x\right)\left(x-\mu\right)^2+p\left(x\right)\log p\left(x\right)\right)dx-\lambda_1-\mu\lambda_2-\sigma^2\lambda_3 \tag{19.51}
\\\end{eqnarray}</script></span></p><p>Để cực tiểu hóa nhân tử Lagrang theo <span class="mathjax"><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>, ta gán các đạo hàm bằng 0:</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
\forall x, \frac{\delta}{\delta p\left(x\right)}\mathcal{L}=\lambda_1+\lambda_2x+\lambda_3\left(x-\mu\right)^2-1-\log p\left(x\right)=0. \tag{19.52}
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
\forall x, \frac{\delta}{\delta p\left(x\right)}\mathcal{L}=\lambda_1+\lambda_2x+\lambda_3\left(x-\mu\right)^2-1-\log p\left(x\right)=0. \tag{19.52}
\\\end{eqnarray}</script></span></p><p>Điều kiện này tiết lộ cho chúng ta dạng hàm của <span class="mathjax"><span class="MathJax_Preview">p(x)</span><script type="math/tex">p(x)</script></span>. Sắp xếp lại phương trình trên bằng các phương pháp đại số, ta có</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
p\left( x \right) = \exp \left( \lambda_1 + \lambda_2 x + \lambda_3\left(x-\mu\right)^2-1\right). \tag{19.53}
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
p\left( x \right) = \exp \left( \lambda_1 + \lambda_2 x + \lambda_3\left(x-\mu\right)^2-1\right). \tag{19.53}
\\\end{eqnarray}</script></span></p><p>Chúng ta chưa bao giờ trực tiếp giả định dạng hàm này cho <span class="mathjax"><span class="MathJax_Preview">p(x)</span><script type="math/tex">p(x)</script></span> mà thực tế ta thu được biểu thức này bằng cách cực tiểu hóa phiếm hàm theo phương pháp giải tích. Để hoàn thành bài toán cực tiểu hóa, ta cần chọn các giá trị <span class="mathjax"><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span> sao cho các điều kiện ràng buộc chắc chắn được thõa mãn. Chúng ta có thể lựa chọn <span class="mathjax"><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span> tùy ý, bởi vì gradient của nhân tử Lagrang theo biến <span class="mathjax"><span class="MathJax_Preview">\lambda</span><script type="math/tex">\lambda</script></span> bằng không miễn là các điều kiện ràng buộc được thõa mãn. Để thỏa mãn các điều kiện ràng buộc, ta có thể chọn <span class="mathjax"><span class="MathJax_Preview">\lambda_1 = 1 - \log(\sigma \sqrt{2\pi})</span><script type="math/tex">\lambda_1 = 1 - \log(\sigma \sqrt{2\pi})</script></span>, <span class="mathjax"><span class="MathJax_Preview">\lambda_2 = 0</span><script type="math/tex">\lambda_2 = 0</script></span>, và <span class="mathjax"><span class="MathJax_Preview">\lambda_3 = -\frac{1}{2\sigma^2}</span><script type="math/tex">\lambda_3 = -\frac{1}{2\sigma^2}</script></span> để có</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
p\left( x \right) = \mathcal{N} \left(x;\mu,\sigma^2 \right). \tag{19.54}
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
p\left( x \right) = \mathcal{N} \left(x;\mu,\sigma^2 \right). \tag{19.54}
\\\end{eqnarray}</script></span></p><p>Đây là một lí do phân phối chuẩn được sử dụng khi phân phối thực chưa biết. Bởi vì phân phối chuẩn có entropy lớn nhất, chúng ta áp đặt số lượng giả thuyết nhỏ nhất có thể với giả định này.</p><p>Khi khảo sát các điểm tới hạn của phiếm hàm Lagrange cho entropy, chúng ta chỉ tìm một điểm tới hạn, tương ứng với cực đại entropy với phương sai cố định. Còn hàm phân phối xác suất <em>cực tiểu hóa</em> entropy thì sao? Tại sao chúng ta không tìm một điểm tới hạn thứ hai tương ứng với cực tiểu của entropy? Lý do là không có một hàm đặc biệt nào đạt được entropy cực tiểu. Khi các hàm số đặt nhiều mật độ xác suất hơn vào hai điểm <span class="mathjax"><span class="MathJax_Preview">x=\mu + \sigma</span><script type="math/tex">x=\mu + \sigma</script></span> và <span class="mathjax"><span class="MathJax_Preview">x=\mu - \sigma</span><script type="math/tex">x=\mu - \sigma</script></span>, và đặt ít mật độ xác suất hơn vào các giá trị khác của <span class="mathjax"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span>, chúng giảm entropy xuống trong khi vẫn giữ nguyên phương sai mong muốn. Tuy nhiên, bất kì hàm số nào đặt chính xác mật độ xác suất bằng không tại mọi điểm ngoại trừ hai điểm nói trên sẽ có tích phân khác 1 và không phải là một phân bố xác suất hợp lệ. Do đó không có hàm phân bố xác suất đơn lẻ nào có entropy nhỏ nhất, cũng giống như không có bất kì số thực dương nhỏ nhất nào. Thay vào đó, chúng ta có thể nói rằng có một chuỗi phân phối xác suất hội tụ đến các hàm chỉ tập trung mật độ vào hai điểm đã nêu. Trường hợp suy biến này có thể mô tả bằng một bộ trộn các phân phối Dirac. Vì các phân phối Dirac không thể được biểu diễn bởi một hàm phân phối xác suất riêng lẻ, không có bất cứ phân phối Dirac hay bộ trộn các phân phối Dirac nào tương ứng với một điểm cụ thể trong không gian hàm. Các phân phối này do đó bất khả kiến với phương pháp của chúng ta trong việc tìm các điểm mà tại đó các đạo hàm phiếm hàm bằng không. Đây là một hạn chế của phương pháp này. Do đó các phân phối như phân phối Dirac phải được tìm ra bằng một phương pháp nào đó khác, như tiên đoán ra chúng rồi chứng minh chúng là đúng chẳng hạn.</p><h2 id="1943-Các-biến-ẩn-liên-tục"><a class="anchor hidden-xs" href="#1943-Các-biến-ẩn-liên-tục" title="1943-Các-biến-ẩn-liên-tục"><span class="octicon octicon-link"></span></a>19.4.3 Các biến ẩn liên tục</h2><p>Một khi các mô hình đồ thị của chúng ta chứa các biến ẩn liên tục, ta có thể tiếp tục thực hiện suy luận biến phân và học biến phân bằng cách cực đại hóa <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span>. Tuy nhiên lúc này chúng ta phải sử dụng các phương pháp tính biến phân khi cực đại hóa <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> theo <span class="mathjax"><span class="MathJax_Preview">q(\boldsymbol{h}\mid\boldsymbol{v})</span><script type="math/tex">q(\boldsymbol{h}\mid\boldsymbol{v})</script></span>.</p><p>Trong hầu hết các trường hợp, các nhà thực nghiệm không cần phải tự giải quyết các vấn đề tính toán biến phân. Thay vào đó, tồn tại một phương trình tổng quát cho việc cập nhật điểm cố định của trường trung bình. Nếu ta đặt xấp xỉ trường trung bình là</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
q\left(\boldsymbol{h}\mid\boldsymbol{v}\right) = \prod_i q\left(h_i\mid\boldsymbol{v}\right), \tag{19.55}
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
q\left(\boldsymbol{h}\mid\boldsymbol{v}\right) = \prod_i q\left(h_i\mid\boldsymbol{v}\right), \tag{19.55}
\\\end{eqnarray}</script></span></p><p>và cố định <span class="mathjax"><span class="MathJax_Preview">q(h_j\mid \boldsymbol{v})</span><script type="math/tex">q(h_j\mid \boldsymbol{v})</script></span> với mọi <span class="mathjax"><span class="MathJax_Preview">j \neq i</span><script type="math/tex">j \neq i</script></span>, khi đó ta có thể thu được <span class="mathjax"><span class="MathJax_Preview">q(h_i\mid \boldsymbol{v})</span><script type="math/tex">q(h_i\mid \boldsymbol{v})</script></span> tối ưu bằng cách chuẩn hóa phân phối chưa chuẩn hoá sau</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
\tilde{q}\left(h_i\mid\boldsymbol{v}\right) = \exp \left(\mathbb{E}_{\mathbf{h}_{-i}\sim q \left(\mathbf{h}_{-i}\mid\boldsymbol{v} \right)} \log\tilde{p} \left(\boldsymbol{v},\boldsymbol{h}\right) \right), \tag{19.56}
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
\tilde{q}\left(h_i\mid\boldsymbol{v}\right) = \exp \left(\mathbb{E}_{\mathbf{h}_{-i}\sim q \left(\mathbf{h}_{-i}\mid\boldsymbol{v} \right)} \log\tilde{p} \left(\boldsymbol{v},\boldsymbol{h}\right) \right), \tag{19.56}
\\\end{eqnarray}</script></span></p><p>miễn là <span class="mathjax"><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span> không gán xác suất 0 cho bất kì tổ hợp biến nào. Thực hiện tính kỳ vọng trong hàm mũ sẽ giúp tìm ra dạng của phân phối <span class="mathjax"><span class="MathJax_Preview">q(h_i|\boldsymbol{v})</span><script type="math/tex">q(h_i|\boldsymbol{v})</script></span>. Suy ra các dạng phiếm hàm của q một cách trực tiếp bằng phương pháp tính biến phân chỉ cần thiết nếu ta muốn phát triển một dạng mới của học biến phân. Phương trình <span class="mathjax"><span class="MathJax_Preview">19.56</span><script type="math/tex">19.56</script></span> đề xuất xấp xỉ trường trung bình cho bất kì mô hình xác suất nào.</p><p>Phương trình <span class="mathjax"><span class="MathJax_Preview">19.56</span><script type="math/tex">19.56</script></span> là một phương trình điểm cố định, được thiết kế để áp dụng lặp đi lặp lại cho mỗi giá trị của <span class="mathjax"><span class="MathJax_Preview">i</span><script type="math/tex">i</script></span> đến khi hội tụ. Tuy nhiên, nó có thể cho chúng ta biết nhiều thông tin hơn. Nó cho chúng ta biết dạng phiếm hàm mà nghiệm tối ưu có thể nhận, không quan trọng việc có thể đạt được điều đó bằng các phương trình điểm cố định hay không. Điều này có nghĩa là chúng ta có thể thu được dạng hàm từ phương trình đó nhưng xem một vài giá trị xuất hiện trong nó như những tham số mà ta có thể tối ưu hóa bằng bất kì phương pháp nào.</p><p>Lấy ví dụ một mô hình thống kê đơn giản với các biến ẩn liên tục  <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h} \in \mathbb{R}^2</span><script type="math/tex">\boldsymbol{h} \in \mathbb{R}^2</script></span> và một biến khả kiến <span class="mathjax"><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>. Giả sử rằng <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h}) = \mathcal{N}(\boldsymbol{h}; 0, \boldsymbol{I})</span><script type="math/tex">p(\boldsymbol{h}) = \mathcal{N}(\boldsymbol{h}; 0, \boldsymbol{I})</script></span> và <span class="mathjax"><span class="MathJax_Preview">p(v|\boldsymbol{h}) = \mathcal{N}(v; \boldsymbol{w}^\top\boldsymbol{h}; 1)</span><script type="math/tex">p(v|\boldsymbol{h}) = \mathcal{N}(v; \boldsymbol{w}^\top\boldsymbol{h}; 1)</script></span>. Thực tế chúng ta có thể đơn giản hóa mô hình này bằng phép lấy tích phân theo <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> để kết quả chỉ đơn giản là một phân phối Gausian theo <span class="mathjax"><span class="MathJax_Preview">v</span><script type="math/tex">v</script></span>. Bản thân mô hình không có gì thú vị, chúng tôi lấy ví dụ này chỉ để chứng minh làm cách nào phương pháp tính biến phân có thể được áp dụng vào mô hình hóa xác suất.</p><p>Xác suất hậu nghiệm thât, với một hằng số chuẩn hóa, được cho bởi:</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
&amp;&amp; p\left(\boldsymbol{h}\mid\boldsymbol{v}\right)\tag{19.57}\\
&amp;\propto&amp;p\left(\boldsymbol{h},\boldsymbol{v}\right) \tag{19.58}\\
&amp;=&amp;p\left(h_1\right)p\left(h_2\right)p\left(\boldsymbol{v}\mid\boldsymbol{h}\right)\tag{19.59}\\
&amp;\propto&amp;\exp\left(-\frac{1}{2}\left[ h_1^2 + h_2^2 + \left(v-h_1w_1-h_2w_2\right)^2  \right]\right)\tag{19.60}\\
&amp;=&amp;\exp\left(h_1^2+h_2^2+v^2+h_1^2w_1^2+h_2^2w_2^2-2vh_1w_1-2vh_2w_2+2h_1w_1h_2w_2\right). \tag{19.61}
\\\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
&& p\left(\boldsymbol{h}\mid\boldsymbol{v}\right)\tag{19.57}\\
&\propto&p\left(\boldsymbol{h},\boldsymbol{v}\right) \tag{19.58}\\
&=&p\left(h_1\right)p\left(h_2\right)p\left(\boldsymbol{v}\mid\boldsymbol{h}\right)\tag{19.59}\\
&\propto&\exp\left(-\frac{1}{2}\left[ h_1^2 + h_2^2 + \left(v-h_1w_1-h_2w_2\right)^2  \right]\right)\tag{19.60}\\
&=&\exp\left(h_1^2+h_2^2+v^2+h_1^2w_1^2+h_2^2w_2^2-2vh_1w_1-2vh_2w_2+2h_1w_1h_2w_2\right). \tag{19.61}
\\\end{eqnarray}</script></span></p><p>Bởi vì sự xuất hiện cùng nhau của các nhân tử <span class="mathjax"><span class="MathJax_Preview">h_1</span><script type="math/tex">h_1</script></span> và <span class="mathjax"><span class="MathJax_Preview">h_2</span><script type="math/tex">h_2</script></span>, chúng ta có thể thấy rằng xác suất hậu nghiệm thực sự không được phân tích thành nhân tố theo <span class="mathjax"><span class="MathJax_Preview">h_1</span><script type="math/tex">h_1</script></span> và <span class="mathjax"><span class="MathJax_Preview">h_2</span><script type="math/tex">h_2</script></span>.<br>
Áp dụng phương trình <span class="mathjax"><span class="MathJax_Preview">19.56</span><script type="math/tex">19.56</script></span>, ta có</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
&amp;&amp; \tilde{q}\left( h_1 \mid \boldsymbol{v} \right) \tag{19.62}\\
&amp;=&amp;\exp\left(\mathbb{E}_{\text{h}_2\sim q\left(\text{h}_2\mid\boldsymbol{v}\right)} \log\tilde{p}\left(\boldsymbol{v}, \boldsymbol{h} \right)\right) \tag{19.63}\\
&amp;=&amp;\exp\left(-\frac{1}{2} \mathbb{E}_{\text{h}_2\sim q\left(\text{h}_2\mid\boldsymbol{v}\right)} \left[h_1^2 + h_2^2 + v^2 + h_1^2w_1^2 +h_2^2w_2^2 \\  \tag{19.64}
-2vh_1w_1 - 2vh_2w_2 + 2h_1w_1h_2w_2 \right] \right). \\ \tag{19.65} \space
\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
&& \tilde{q}\left( h_1 \mid \boldsymbol{v} \right) \tag{19.62}\\
&=&\exp\left(\mathbb{E}_{\text{h}_2\sim q\left(\text{h}_2\mid\boldsymbol{v}\right)} \log\tilde{p}\left(\boldsymbol{v}, \boldsymbol{h} \right)\right) \tag{19.63}\\
&=&\exp\left(-\frac{1}{2} \mathbb{E}_{\text{h}_2\sim q\left(\text{h}_2\mid\boldsymbol{v}\right)} \left[h_1^2 + h_2^2 + v^2 + h_1^2w_1^2 +h_2^2w_2^2 \\  \tag{19.64}
-2vh_1w_1 - 2vh_2w_2 + 2h_1w_1h_2w_2 \right] \right). \\ \tag{19.65} \space
\end{eqnarray}</script></span></p><p>Từ đây ta có thể nhận ra rằng thực tế chỉ có hai giá trị chúng ta cần đạt được từ <span class="mathjax"><span class="MathJax_Preview">q(h_2|\boldsymbol{v}): \mathbb{E}_{\text{h}_2\sim q(\text{h}_2\mid\boldsymbol{v})} [h_2]</span><script type="math/tex">q(h_2|\boldsymbol{v}): \mathbb{E}_{\text{h}_2\sim q(\text{h}_2\mid\boldsymbol{v})} [h_2]</script></span> và <span class="mathjax"><span class="MathJax_Preview">\mathbb{E}_{\text{h}_2\sim q(\text{h}_2\mid\boldsymbol{v})} [h_2^2]</span><script type="math/tex">\mathbb{E}_{\text{h}_2\sim q(\text{h}_2\mid\boldsymbol{v})} [h_2^2]</script></span>. Viết lại các biểu thức này thành <span class="mathjax"><span class="MathJax_Preview">\langle h_2\rangle</span><script type="math/tex">\langle h_2\rangle</script></span> và <span class="mathjax"><span class="MathJax_Preview">\langle h_2^2\rangle</span><script type="math/tex">\langle h_2^2\rangle</script></span>, ta có</p><p><span class="mathjax"><span class="MathJax_Preview">\begin{eqnarray}
\tilde{q}\left( h_1 \mid \boldsymbol{v} \right) 
&amp;= \exp \left(-\frac{1}{2} \left[h_1^2 + \langle h_2^2\rangle + v^2 + h_1^2w_1^2 +\langle h_2^2\rangle w_2^2 \tag{19.66}\\
-2vh_1w_1 - 2v\langle h_2\rangle w_2 + 2h_1w_1\langle h_2\rangle w_2 \right] \right). \\ \tag{19.67} \space
\end{eqnarray}</span><script type="math/tex; mode=display">\begin{eqnarray}
\tilde{q}\left( h_1 \mid \boldsymbol{v} \right) 
&= \exp \left(-\frac{1}{2} \left[h_1^2 + \langle h_2^2\rangle + v^2 + h_1^2w_1^2 +\langle h_2^2\rangle w_2^2 \tag{19.66}\\
-2vh_1w_1 - 2v\langle h_2\rangle w_2 + 2h_1w_1\langle h_2\rangle w_2 \right] \right). \\ \tag{19.67} \space
\end{eqnarray}</script></span></p><p>Từ đây ta có thể thấy rằng <span class="mathjax"><span class="MathJax_Preview">\tilde{q}</span><script type="math/tex">\tilde{q}</script></span> có dạng phiếm hàm Gauss. Do đó ta có thể kết luận rằng <span class="mathjax"><span class="MathJax_Preview">q(\boldsymbol{h}|\boldsymbol{v}) = \mathcal{N}(\boldsymbol{h};\boldsymbol{\mu}, \boldsymbol{\beta}^{-1})</span><script type="math/tex">q(\boldsymbol{h}|\boldsymbol{v}) = \mathcal{N}(\boldsymbol{h};\boldsymbol{\mu}, \boldsymbol{\beta}^{-1})</script></span> với <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\mu}</span><script type="math/tex">\boldsymbol{\mu}</script></span> và ma trận đường chéo <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\beta}</span><script type="math/tex">\boldsymbol{\beta}</script></span> là các tham số biến phân có thể tối ưu bằng bất kì kĩ thuật nào. Điều quan trọng cần nhắc lại là chúng ta chưa bao giờ giả định <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> có dạng Gaussian; dạng Gaussian của nó thu được một cách tự động bằng các phép tính biến phân khi tối ưu <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> theo <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span>. Sử dụng cùng cách tiếp cận như vậy trên các mô hình khác nhau có thể sinh ra các dạng hàm khác nhau của <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>.</p><p>Trường hợp trên dĩ nhiên chỉ là một ví dụ minh hoạ đơn giản. Để biết thêm về các ứng dụng thực tế của học biến phân với các biến ẩn liên tục trong bối cảnh học sâu, xem Goodfellow cùng cộng sự. (2013d).</p><p>-----------------------<br>
Hưng Nguyễn kết thúc dịch từ đây (hết trang 647)<br>
-----------------------</p><h2 id="1944-Tương-tác-giữa-Học-và-Suy-luận"><a class="anchor hidden-xs" href="#1944-Tương-tác-giữa-Học-và-Suy-luận" title="1944-Tương-tác-giữa-Học-và-Suy-luận"><span class="octicon octicon-link"></span></a>19.4.4 Tương tác giữa Học và Suy luận</h2><p>Việc sử dụng phương pháp suy luận xấp xỉ trong một thuật toán học gây ảnh hưởng đến tiến trình học, và đến cả độ chính xác của chính thuật toán suy luận.<br>
Cụ thể là, thuật toán huấn luyện có xu hướng phỏng theo mô hình bằng cách làm cho các giả định xấp xỉ bên dưới thuật toán suy luận xấp xỉ trở nên chính xác hơn. Khi huấn luyện các tham số, học biến phân làm tăng giá trị</p><p><span class="mathjax"><span class="MathJax_Preview">\mathbb{E}_{\mathbf{h} \sim q} log p(\boldsymbol{v, h}). \tag{19.68}</span><script type="math/tex; mode=display">\mathbb{E}_{\mathbf{h} \sim q} log p(\boldsymbol{v, h}). \tag{19.68}</script></span></p><p>Với một giá trị <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span> cụ thể, điều này có nghĩa là nó tăng <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h}\mid\boldsymbol{v})</span><script type="math/tex">p(\boldsymbol{h}\mid\boldsymbol{v})</script></span> cho những giá trị <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> có xác suất <span class="mathjax"><span class="MathJax_Preview">q(\boldsymbol{h}\mid\boldsymbol{v})</span><script type="math/tex">q(\boldsymbol{h}\mid\boldsymbol{v})</script></span> cao và giảm <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h}\mid\boldsymbol{v})</span><script type="math/tex">p(\boldsymbol{h}\mid\boldsymbol{v})</script></span> cho những giá trị <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> có xác suất <span class="mathjax"><span class="MathJax_Preview">q(\boldsymbol{h}\mid\boldsymbol{v})</span><script type="math/tex">q(\boldsymbol{h}\mid\boldsymbol{v})</script></span> thấp.</p><p>Hành vi này làm cho các giả định xấp xỉ trở thành những lời tiên tri tự ứng nghiệm. Nếu chúng ta huấn luyện một mô hình với một hậu nghiệm xấp xỉ đơn mode, chúng ta sẽ thu được một mô hình với một hậu nghiệm thực gần với đơn mode hơn nhiều so với mô hình mà ta đạt được nếu huấn luyện với suy luận chính xác.</p><blockquote>
<p>DN đã xem đến đây</p>
</blockquote><p>Tính toán chính xác độ mất mát trên một mô hình được huấn luyện bởi xấp xỉ biến phân do đó là rất khó khăn. Có một vài phương pháp để ước lượng <span class="mathjax"><span class="MathJax_Preview">\log p(v)</span><script type="math/tex">\log p(v)</script></span>. Thường thì chúng ta có thể ước tính <span class="mathjax"><span class="MathJax_Preview">\log p(v,θ)</span><script type="math/tex">\log p(v,θ)</script></span> sau khi huấn luyện mô hình và nhận thấy rằng sự chênh lệch so với <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}(\boldsymbol{v},\boldsymbol{\theta},q)</span><script type="math/tex">\mathcal{L}(\boldsymbol{v},\boldsymbol{\theta},q)</script></span> là không đáng kể. Từ điều này, ta có thể kết luận rằng phép xấp xỉ biến phân là chính xác đối với giá trị <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta}</span><script type="math/tex">\boldsymbol{\theta}</script></span> nhất định mà ta thu được từ tiến trình học. Chúng ta không thể kết luận xấp xỉ biến phân này chính xác một cách tổng quát cũng như không thể kết luận rằng xấp xỉ biến phân đã không gây thiệt hại đáng kể cho tiến trình học. Để tính được độ mất mát thực sự gây ra bởi xấp xỉ biến phân, chúng ta cần biết giá trị của <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta}^\star</span><script type="math/tex">\boldsymbol{\theta}^\star</script></span> = <span class="mathjax"><span class="MathJax_Preview">\max_{\boldsymbol{\theta}} \log p(\boldsymbol{v};\boldsymbol{\theta})</span><script type="math/tex">\max_{\boldsymbol{\theta}} \log p(\boldsymbol{v};\boldsymbol{\theta})</script></span>. Hai điều kiện sau có thể đồng thời xảy ra: <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}(\boldsymbol{v},\boldsymbol{\theta},q) \approx \log p(v;θ)</span><script type="math/tex">\mathcal{L}(\boldsymbol{v},\boldsymbol{\theta},q) \approx \log p(v;θ)</script></span> và <span class="mathjax"><span class="MathJax_Preview">\log p(\boldsymbol{v};\boldsymbol{\theta}) \ll \log p(\boldsymbol{v};\boldsymbol{\theta}^\star)</span><script type="math/tex">\log p(\boldsymbol{v};\boldsymbol{\theta}) \ll \log p(\boldsymbol{v};\boldsymbol{\theta}^\star)</script></span>. Nếu <span class="mathjax"><span class="MathJax_Preview">\max_q \mathcal{L}(\boldsymbol{v},\boldsymbol{\theta}^\star,q) \ll \log p(\boldsymbol{v};\boldsymbol{\theta}^\star)</span><script type="math/tex">\max_q \mathcal{L}(\boldsymbol{v},\boldsymbol{\theta}^\star,q) \ll \log p(\boldsymbol{v};\boldsymbol{\theta}^\star)</script></span>, vì <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta}^\star)</span><script type="math/tex">\boldsymbol{\theta}^\star)</script></span> khiến phân phối hậu nghiệm trở nên quá phức tạp để họ phân phối <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> của chúng ta có thể dung nạp, khi đó tiến trình học sẽ không bao giờ tiến gần đến giá trị <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta}^\star</span><script type="math/tex">\boldsymbol{\theta}^\star</script></span>. Một vấn đề như thế rất khó được phát hiện, bởi vì chúng ta chỉ có thể biết chắc chắn điều gì đã xảy ra nếu như có một thuật toán ưu việt có thể tìm ra <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta}^\star</span><script type="math/tex">\boldsymbol{\theta}^\star</script></span> để so sánh.</p><h1 id="195-Suy-luận-xấp-xỉ-được-học"><a class="anchor hidden-xs" href="#195-Suy-luận-xấp-xỉ-được-học" title="195-Suy-luận-xấp-xỉ-được-học"><span class="octicon octicon-link"></span></a>19.5 Suy luận xấp xỉ được học</h1><p>Chúng ta đã thấy rằng suy luận có thể được xem như một thủ tục tối ưu hóa làm tăng giá trị của một hàm <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span>. Thực hiện tối ưu hóa một cách tường minh thông qua thủ tục lặp như phương trình điểm cố định hay tối ưu hoá dựa trên gradient sẽ rất tốn kém và mất thời giờ. Nhiều phương án suy luận tránh hao phí bằng cách học để thực hiện suy luận xấp xỉ. Cụ thể, chúng ta có thể xem quá trình tối ưu hóa như một hàm <span class="mathjax"><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> ánh xạ một đầu vào <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span> vào một phân phối xấp xỉ <span class="mathjax"><span class="MathJax_Preview">q^\star = \arg \max_q \mathcal{L}(\boldsymbol{v},q)</span><script type="math/tex">q^\star = \arg \max_q \mathcal{L}(\boldsymbol{v},q)</script></span>. Một khi xem quá trình tối ưu hoá lặp đa bước như một hàm số, chúng ta có thể xấp xỉ nó với một mạng neuron hiện thực hàm xấp xỉ <span class="mathjax"><span class="MathJax_Preview">\hat{f}(\boldsymbol{v},\boldsymbol{\theta})</span><script type="math/tex">\hat{f}(\boldsymbol{v},\boldsymbol{\theta})</script></span>.</p><h2 id="1951-Thức-Ngủ-Wake-Sleep"><a class="anchor hidden-xs" href="#1951-Thức-Ngủ-Wake-Sleep" title="1951-Thức-Ngủ-Wake-Sleep"><span class="octicon octicon-link"></span></a>19.5.1 Thức-Ngủ (Wake-Sleep)</h2><p>Một trong những khó khăn chính khi huấn luyện một mô hình để suy luận <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> từ <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span> là chúng ta không có một tập huấn luyện có giám sát để huấn luyện mô hình. Với một giá trị <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span> chúng ta không biết <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> tương ứng. Sự ánh xạ từ <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span> sang <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> phụ thuộc vào họ mô hình được lựa chọn, và tiến hoá trong xuyên suốt quá trình học khi <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta}</span><script type="math/tex">\boldsymbol{\theta}</script></span> thay đổi. Thuật toán thức-ngủ (Hinton cùng cộng sự, 1995b; Frey cùng cộng sự 1996) giải quyết vấn đề này bằng việc lấy mẫu của cả <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> và <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span> từ phân phối mô hình. Ví dụ, trong một mô hình có hướng, công việc này có thể được thực hiện một cách ít tốn kém bằng cách thực hiện phép lấy mẫu di truyền bắt đầu từ <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> và kết thúc ở <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span>. Mạng suy luận sau đó có thể được huấn luyện để thực hiện ánh xạ ngược: dự đoán <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> nào là nguyên nhân của <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span> hiện có. Hạn chế duy nhất của phương pháp này là chúng ta chỉ có khả năng huấn luyện mạng suy luận trên những giá trị <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span> có xác suất cao theo phân phối mô hình. Khi quá trình học mới bắt đầu, phân phối mô hình sẽ không giống phân phối dữ liệu, mạng suy luận vì vậy sẽ không có cơ hội để học trên những mẫu giống với dữ liệu.</p><p>Trong phần 18.2, chúng ta đã biết rằng một giải thích khả dĩ cho vai trò của ngủ mơ đối với con người và động vật là các giấc mơ có thể cung cấp những mẫu pha âm mà các thuật toán huấn luyện Monte Carlo sử dụng để ước tính gradient âm của logarit hàm phân hoạch trong các mô hình vô hướng. Một cách giải thích khả dĩ khác cho giấc mơ sinh học đó là nó đang cung cấp các mẫu từ <span class="mathjax"><span class="MathJax_Preview">p(\boldsymbol{h},\boldsymbol{v})</span><script type="math/tex">p(\boldsymbol{h},\boldsymbol{v})</script></span> mà các mẫu này có thể được sử dụng để huấn luyện một mô hình mạng suy luận để dự đoán <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{h}</span><script type="math/tex">\boldsymbol{h}</script></span> khi biết <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{v}</span><script type="math/tex">\boldsymbol{v}</script></span>. Cách giải thích này theo khía cạnh nào đó có vẻ hợp lý hơn cách giải thích dựa trên hàm phân hoạch. Các thuật toán Monte Carlo thường không hiệu quả nếu chúng chỉ chạy với pha dương của gradient trong một vài bước và sau đó là với pha âm trong một vài bước tiếp theo. Loài người và động vật đều có thể thức hay ngủ trong nhiều giờ liên tục. Chúng ta vẫn chưa rõ liệu nhịp sinh hoạt này có thể hỗ trợ việc học Monte Carlo của một mô hình vô hướng hay không. Những thuật toán học dựa trên cực đại hóa <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> có thể được chạy trên những thời đoạn kéo dài để cải thiện <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> cũng như trên những thời đoạn kéo dài để cải thiện <span class="mathjax"><span class="MathJax_Preview">\boldsymbol{\theta}</span><script type="math/tex">\boldsymbol{\theta}</script></span>. Nếu vai trò của giấc mơ sinh học là huấn luyện những mạng dự đoán <span class="mathjax"><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>, thì điều này giải thích tại sao các loài động vật có khả năng thức trong nhiều giờ đồng hồ (thời gian thức càng thức lâu thì khoảng cách giữa <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> và <span class="mathjax"><span class="MathJax_Preview">\log p(\boldsymbol{v})</span><script type="math/tex">\log p(\boldsymbol{v})</script></span> càng lớn, tuy nhiên <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span> sẽ luôn là một cận dưới) cũng như duy trì giấc ngủ ( một mô hình sinh mẫu sẽ không tự điều chỉnh trong khi ngủ) mà không gây hại đến các mô hình nội bộ. Tất nhiên, những ý tưởng này hoàn toàn là các phỏng đoán, đồng thời không có một minh chứng rõ ràng nào về việc giấc mơ hoàn thành một trong những mục tiêu trên. Giấc mơ cũng có thể giúp học tăng cường hơn là mô hình hóa xác suất, bằng việc lấy mẫu các kinh nghiệm nhân tạo từ những mô hình chuyển tiếp của động vật để huấn luyện chuyến thuật của động vật đó. Hoặc giấc ngủ có thể phục vụ những mục đích khác vẫn chưa được khám phá bởi cộng đồng học máy.</p><h2 id="1952-Các-dạng-khác-của-Suy-luận-được-học"><a class="anchor hidden-xs" href="#1952-Các-dạng-khác-của-Suy-luận-được-học" title="1952-Các-dạng-khác-của-Suy-luận-được-học"><span class="octicon octicon-link"></span></a>19.5.2 Các dạng khác của Suy luận được học</h2><p>Chiến lược này của suy luận xấp xỉ được học cũng đã được áp dụng cho các mô hình khác. Salakhutdinov và Larochelle (2010) đã chỉ ra rằng chạy một lần qua mạng suy luận đã được học có thể cho ra suy luận nhanh hơn là lặp qua các phương trình điểm cố định của trường trung bình trong một DBM. Thủ tục huấn luyện dựa trên việc vận hành một mạng suy luận, sau đó áp dụng một bước của trường trung bình để cải thiện các ước lượng của nó, và huấn luyện mạng suy luận để mạng này xuất ra ước lượng đã được tinh chỉnh thay vì ước lượng nguyên gốc của nó.</p><p>Như chúng ta đã thấy trong phần 14.8, mô hình phân rã thưa tiên đoán huấn luyện một mạng mã hóa nông để dự đoán mã thưa cho dữ liệu đầu vào. Điều này có thể được xem như một sự lai ghép giữa bộ tự mã hóa và bộ mã hóa thưa. Ta có thể định nghĩa các ngữ học xác xuất cho mô hình, mà theo chúng bộ mã hóa có thể được xem như là thực hiện suy luận MAP xấp xỉ được học. Do bộ mã hóa nông của nó, PSD không có khả năng hiện thực sự cạnh tranh giữa các đơn vị mà chúng ta đã thấy trong suy luận trường trung bình. Tuy nhiên, vấn đề này có thể được giải quyết bằng cách huấn luyện một bộ mã hóa đa tầng để thực hiện suy luận xấp xỉ được học, như trong phương pháp ITSA (Greror và LeCun, 2010b).</p><p>Suy luận xấp xỉ được học gần đây đã trở thành một trong những hướng tiếp cận chủ đạo của mô hình hoá sinh mẫu, dưới dạng của tự mã hóa biến phân (Kingma, 2013; Rezende cùng cộng sự, 2014). Theo phương pháp tiếp cận khéo léo này, ta không cần phải kiến trúc các mục tiêu rõ ràng cho mạng suy luận. Thay vào đó, mạng suy luận chỉ đơn giản được sử dụng để định ra <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span>, rồi sau đó các tham số của mạng suy luận sẽ được điều chỉnh để tăng giá trị của <span class="mathjax"><span class="MathJax_Preview">\mathcal{L}</span><script type="math/tex">\mathcal{L}</script></span>. Mô hình này được miêu tả sâu hơn trong phần 20.10.3.</p><p>Nhờ sử dụng suy luận xấp xỉ, chúng ta có thể huấn luyện và sử dụng nhiều loại mô hình khác nhau. Những mô hình như vậy sẽ được miêu tả trong chương sau.</p><p>—Tuấn Phạm kết thúc dịch  ở đây ( hết trang 650)</p></div>
    <div class="ui-toc dropup unselectable hidden-print" style="display:none;">
        <div class="pull-right dropdown">
            <a id="tocLabel" class="ui-toc-label btn btn-default" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false" title="Table of content">
                <i class="fa fa-bars"></i>
            </a>
            <ul id="ui-toc" class="ui-toc-dropdown dropdown-menu" aria-labelledby="tocLabel">
                <div class="toc"><ul class="nav">
<li class=""><a href="#Chương-19-suy-luận-xấp-xỉ" title="Chương 19: suy luận xấp xỉ">Chương 19: suy luận xấp xỉ</a><ul class="nav">
<li><a href="#191-Suy-luận-như-là-Tối-ưu-hóa" title="19.1 Suy luận như là Tối ưu hóa">19.1 Suy luận như là Tối ưu hóa</a></li>
<li><a href="#192-Cực-đại-hoá-kỳ-vọng" title="19.2 Cực đại hoá kỳ vọng">19.2 Cực đại hoá kỳ vọng</a></li>
</ul>
</li>
<li><a href="#193-Suy-luận-MAP-và-mã-hoá-thưa" title="19.3 Suy luận MAP và mã hoá thưa">19.3 Suy luận MAP và mã hoá thưa</a><ul class="nav">
<li><a href="#194-Suy-luận-biến-phân-và-học-biến-phân" title="19.4 Suy luận biến phân và học biến phân">19.4 Suy luận biến phân và học biến phân</a></li>
<li><a href="#1941-Các-biến-ẩn-rời-rạc" title="19.4.1 Các biến ẩn rời rạc">19.4.1 Các biến ẩn rời rạc</a></li>
<li><a href="#1942-Phương-pháp-tính-các-biến-phân" title="19.4.2 Phương pháp tính các biến phân">19.4.2 Phương pháp tính các biến phân</a></li>
<li><a href="#1943-Các-biến-ẩn-liên-tục" title="19.4.3 Các biến ẩn liên tục">19.4.3 Các biến ẩn liên tục</a></li>
<li><a href="#1944-Tương-tác-giữa-Học-và-Suy-luận" title="19.4.4 Tương tác giữa Học và Suy luận">19.4.4 Tương tác giữa Học và Suy luận</a></li>
</ul>
</li>
<li><a href="#195-Suy-luận-xấp-xỉ-được-học" title="19.5 Suy luận xấp xỉ được học">19.5 Suy luận xấp xỉ được học</a><ul class="nav">
<li><a href="#1951-Thức-Ngủ-Wake-Sleep" title="19.5.1 Thức-Ngủ (Wake-Sleep)">19.5.1 Thức-Ngủ (Wake-Sleep)</a></li>
<li><a href="#1952-Các-dạng-khác-của-Suy-luận-được-học" title="19.5.2 Các dạng khác của Suy luận được học">19.5.2 Các dạng khác của Suy luận được học</a></li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
            </ul>
        </div>
    </div>
    <div id="ui-toc-affix" class="ui-affix-toc ui-toc-dropdown unselectable hidden-print" data-spy="affix" style="top:17px;display:none;"  >
        <div class="toc"><ul class="nav">
<li class=""><a href="#Chương-19-suy-luận-xấp-xỉ" title="Chương 19: suy luận xấp xỉ">Chương 19: suy luận xấp xỉ</a><ul class="nav">
<li><a href="#191-Suy-luận-như-là-Tối-ưu-hóa" title="19.1 Suy luận như là Tối ưu hóa">19.1 Suy luận như là Tối ưu hóa</a></li>
<li><a href="#192-Cực-đại-hoá-kỳ-vọng" title="19.2 Cực đại hoá kỳ vọng">19.2 Cực đại hoá kỳ vọng</a></li>
</ul>
</li>
<li><a href="#193-Suy-luận-MAP-và-mã-hoá-thưa" title="19.3 Suy luận MAP và mã hoá thưa">19.3 Suy luận MAP và mã hoá thưa</a><ul class="nav">
<li><a href="#194-Suy-luận-biến-phân-và-học-biến-phân" title="19.4 Suy luận biến phân và học biến phân">19.4 Suy luận biến phân và học biến phân</a></li>
<li><a href="#1941-Các-biến-ẩn-rời-rạc" title="19.4.1 Các biến ẩn rời rạc">19.4.1 Các biến ẩn rời rạc</a></li>
<li><a href="#1942-Phương-pháp-tính-các-biến-phân" title="19.4.2 Phương pháp tính các biến phân">19.4.2 Phương pháp tính các biến phân</a></li>
<li><a href="#1943-Các-biến-ẩn-liên-tục" title="19.4.3 Các biến ẩn liên tục">19.4.3 Các biến ẩn liên tục</a></li>
<li><a href="#1944-Tương-tác-giữa-Học-và-Suy-luận" title="19.4.4 Tương tác giữa Học và Suy luận">19.4.4 Tương tác giữa Học và Suy luận</a></li>
</ul>
</li>
<li><a href="#195-Suy-luận-xấp-xỉ-được-học" title="19.5 Suy luận xấp xỉ được học">19.5 Suy luận xấp xỉ được học</a><ul class="nav">
<li><a href="#1951-Thức-Ngủ-Wake-Sleep" title="19.5.1 Thức-Ngủ (Wake-Sleep)">19.5.1 Thức-Ngủ (Wake-Sleep)</a></li>
<li><a href="#1952-Các-dạng-khác-của-Suy-luận-được-học" title="19.5.2 Các dạng khác của Suy luận được học">19.5.2 Các dạng khác của Suy luận được học</a></li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous" defer></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.6.0/gist-embed.min.js" integrity="sha256-KyF2D6xPIJUW5sUDSs93vWyZm+1RzIpKCexxElmxl8g=" crossorigin="anonymous" defer></script>
    <script>
        var markdown = $(".markdown-body");
        //smooth all hash trigger scrolling
        function smoothHashScroll() {
            var hashElements = $("a[href^='#']").toArray();
            for (var i = 0; i < hashElements.length; i++) {
                var element = hashElements[i];
                var $element = $(element);
                var hash = element.hash;
                if (hash) {
                    $element.on('click', function (e) {
                        // store hash
                        var hash = this.hash;
                        if ($(hash).length <= 0) return;
                        // prevent default anchor click behavior
                        e.preventDefault();
                        // animate
                        $('body, html').stop(true, true).animate({
                            scrollTop: $(hash).offset().top
                        }, 100, "linear", function () {
                            // when done, add hash to url
                            // (default click behaviour)
                            window.location.hash = hash;
                        });
                    });
                }
            }
        }

        smoothHashScroll();
        var toc = $('.ui-toc');
        var tocAffix = $('.ui-affix-toc');
        var tocDropdown = $('.ui-toc-dropdown');
        //toc
        tocDropdown.click(function (e) {
            e.stopPropagation();
        });

        var enoughForAffixToc = true;

        function generateScrollspy() {
            $(document.body).scrollspy({
                target: ''
            });
            $(document.body).scrollspy('refresh');
            if (enoughForAffixToc) {
                toc.hide();
                tocAffix.show();
            } else {
                tocAffix.hide();
                toc.show();
            }
            $(document.body).scroll();
        }

        function windowResize() {
            //toc right
            var paddingRight = parseFloat(markdown.css('padding-right'));
            var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight));
            toc.css('right', right + 'px');
            //affix toc left
            var newbool;
            var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2;
            //for ipad or wider device
            if (rightMargin >= 133) {
                newbool = true;
                var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2;
                var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin;
                tocAffix.css('left', left + 'px');
            } else {
                newbool = false;
            }
            if (newbool != enoughForAffixToc) {
                enoughForAffixToc = newbool;
                generateScrollspy();
            }
        }
        $(window).resize(function () {
            windowResize();
        });
        $(document).ready(function () {
            windowResize();
            generateScrollspy();
        });

        //remove hash
        function removeHash() {
            window.location.hash = '';
        }

        var backtotop = $('.back-to-top');
        var gotobottom = $('.go-to-bottom');

        backtotop.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToTop)
                scrollToTop();
            removeHash();
        });
        gotobottom.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToBottom)
                scrollToBottom();
            removeHash();
        });

        var toggle = $('.expand-toggle');
        var tocExpand = false;

        checkExpandToggle();
        toggle.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            tocExpand = !tocExpand;
            checkExpandToggle();
        })

        function checkExpandToggle () {
            var toc = $('.ui-toc-dropdown .toc');
            var toggle = $('.expand-toggle');
            if (!tocExpand) {
                toc.removeClass('expand');
                toggle.text('Expand all');
            } else {
                toc.addClass('expand');
                toggle.text('Collapse all');
            }
        }

        function scrollToTop() {
            $('body, html').stop(true, true).animate({
                scrollTop: 0
            }, 100, "linear");
        }

        function scrollToBottom() {
            $('body, html').stop(true, true).animate({
                scrollTop: $(document.body)[0].scrollHeight
            }, 100, "linear");
        }
    </script>
</body>

</html>
